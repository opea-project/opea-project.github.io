<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Open Platform for Enterprise AI (OPEA) Framework Draft Proposal &mdash; OPEA™ 1.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../_static/opea-custom.css?v=0eef7f70" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />

  
    <link rel="shortcut icon" href="../_static/OPEA-favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=56dcb7b8"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/opea-custom.js?v=32c45995"></script>
        <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Getting Started with OPEA" href="../getting-started/README.html" />
    <link rel="prev" title="OPEA Overview" href="../introduction/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            OPEA™
              <img src="../_static/opea-horizontal-white-w200.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> OPEA Project</span>
      v: 1.1
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Document Versions</dt>
        
          <dd><a href="/latest/">latest</a></dd>
        
          <dd><a href="/1.0/">1.0</a></dd>
        
          <dd><a href="/1.1/">1.1</a></dd>
        
      </dl>
      <dl>
        <dt>OPEA Project links</dt>
          <dd>
            <a href="https://opea.dev">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/opea-project/docs/wiki">Wiki</a>
          </dd>
      </dl>
    </div>
  </div>
  
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Documentation Home</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../introduction/index.html">OPEA Overview</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction/index.html#opea-project-architecture">OPEA Project Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../introduction/index.html#microservices-flexible-and-scalable-architecture">Microservices: Flexible and Scalable Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../introduction/index.html#megaservices-a-comprehensive-solution">Megaservices: A Comprehensive Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../introduction/index.html#gateways-customized-access-to-mega-and-microservices">Gateways: Customized Access to Mega- and Microservices</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../introduction/index.html#next-step">Next Step</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Open Platform for Enterprise AI (OPEA) Framework Draft Proposal</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#summary">1. Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">2. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#framework-components-architecture-and-flow">3. Framework Components, Architecture and Flow</a></li>
<li class="toctree-l4"><a class="reference internal" href="#assessing-genai-components-and-flows">4. Assessing GenAI components and flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="#grading-structure">5. Grading Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reference-flows">6. Reference flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-a-draft-opea-specifications">Appendix A – Draft OPEA Specifications</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/README.html">Getting Started with OPEA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/README.html#understanding-opea-s-core-components">Understanding OPEA’s Core Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/README.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/README.html#create-and-configure-a-virtual-server">Create and Configure a Virtual Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/README.html#deploy-the-chatqna-solution">Deploy the ChatQnA Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../getting-started/README.html#interact-with-chatqna">Interact with ChatQnA</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started/README.html#whats-next">What’s Next</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../getting-started/README.html#get-involved">Get Involved</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">GenAI Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html">ChatQnA Sample Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#purpose">Purpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#key-implementation-details">Key Implementation Details</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#how-it-works">How It Works</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#expected-output">Expected Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#validation-matrix-and-prerequisites">Validation Matrix and Prerequisites</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#architecture">Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#microservice-outline-and-diagram">Microservice Outline and Diagram</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#deployment">Deployment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/deploy/index.html">ChatQnA Deployment Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#troubleshooting">Troubleshooting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#monitoring">Monitoring</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#set-up-the-prometheus-server">Set Up the Prometheus Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#set-up-the-grafana-dashboard">Set Up the Grafana Dashboard</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/ChatQnA/ChatQnA_Guide.html#summary-and-next-steps">Summary and Next Steps</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html">AgentQnA Sample Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html#purpose">Purpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html#how-it-works">How It Works</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html#deployment">Deployment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/AgentQnA/AgentQnA_Guide.html#single-node">Single Node</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/CodeGen/CodeGen_Guide.html">Codegen Sample Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/CodeGen/CodeGen_Guide.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/CodeGen/CodeGen_Guide.html#purpose">Purpose</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/CodeGen/CodeGen_Guide.html#how-it-works">How It Works</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/CodeGen/CodeGen_Guide.html#deployment">Deployment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/CodeGen/deploy/index.html">CodeGen Deployment Options</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIExamples/README.html">Generative AI Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#architecture">Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/README.html#deployment-guide">Deployment Guide</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#supported-examples">Supported Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#contributing-to-opea">Contributing to OPEA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/examples.html">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#agentqna-application">AgentQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AgentQnA/README.html">Agents for Question Answering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AgentQnA/docker_compose/intel/cpu/xeon/README.html">Single node on-prem deployment with Docker Compose on Xeon Scalable processors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AgentQnA/docker_compose/intel/hpu/gaudi/README.html">Single node on-prem deployment AgentQnA on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AgentQnA/retrieval_tool/README.html">Retrieval tool for agent</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#audioqna-application">AudioQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/README.html">AudioQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/benchmark/accuracy/README.html">AudioQnA Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/benchmark/performance/README.html">AudioQnA Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of AudioQnA on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/docker_compose/intel/hpu/gaudi/README.html">Build Mega Service of AudioQnA on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/kubernetes/intel/README.html">Deploy AudioQnA in a Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/kubernetes/intel/README_gmc.html">Deploy AudioQnA in Kubernetes Cluster on Xeon and Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AudioQnA/ui/svelte/README.html">AudioQnA</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#avatarchatbot-application">AvatarChatbot Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AvatarChatbot/README.html">AvatarChatbot Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AvatarChatbot/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of AvatarChatbot on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/AvatarChatbot/docker_compose/intel/hpu/gaudi/README.html">Build Mega Service of AvatarChatbot on Gaudi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#chatqna-application">ChatQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/README.html">ChatQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/benchmark/accuracy/README.html">ChatQnA Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/benchmark/performance-deprecated/README.html">ChatQnA Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/benchmark/performance-deprecated/helm_charts/README.html">ChatQnA Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/benchmark/performance/kubernetes/intel/gaudi/README.html">ChatQnA Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/amd/gpu/rocm/README.html">Build and deploy CodeGen Application on AMD GPU (ROCm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/cpu/aipc/README.html">Build Mega Service of ChatQnA on AIPC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of ChatQnA on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/cpu/xeon/README_pinecone.html">Build Mega Service of ChatQnA (with Pinecone) on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/cpu/xeon/README_qdrant.html">Build Mega Service of ChatQnA (with Qdrant) on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of ChatQnA on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/intel/hpu/gaudi/how_to_validate_service.html">How to Check and Validate Micro Service in the GenAI Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/docker_compose/nvidia/gpu/README.html">Build MegaService of ChatQnA on NVIDIA GPU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/kubernetes/intel/README.html">Deploy ChatQnA in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/kubernetes/intel/README_gmc.html">Deploy ChatQnA in Kubernetes Cluster on Xeon and Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/kubernetes/intel/README_single_node.html">Deploy ChatQnA in Kubernetes Cluster on Single Node environment (Minikube)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/ui/react/README.html">ChatQnA Conversational UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ChatQnA/ui/svelte/README.html">ChatQnA Customized UI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#codegen-application">CodeGen Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/README.html">Code Generation Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/benchmark/accuracy/README.html">CodeGen Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/benchmark/performance/README.html">CodeGen Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/docker_compose/amd/gpu/rocm/README.html">Build and deploy CodeGen Application on AMD GPU (ROCm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/docker_compose/amd/gpu/rocm/README.html#validate-the-microservices-and-megaservice">Validate the MicroServices and MegaService</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/docker_compose/intel/cpu/xeon/README.html">Build MegaService of CodeGen on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of CodeGen on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/kubernetes/intel/README.html">Deploy CodeGen in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/kubernetes/intel/README_gmc.html">Deploy CodeGen in a Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/kubernetes/intel/cpu/xeon/manifest/README_react_ui.html">Deploy CodeGen with ReactUI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/ui/react/README.html">Code Gen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeGen/ui/svelte/README.html">Code Gen</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#codetrans-application">CodeTrans Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/README.html">Code Translation Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/benchmark/performance/README.html">CodeTrans Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/docker_compose/amd/gpu/rocm/README.html">Build and deploy CodeTrans Application on AMD GPU (ROCm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/docker_compose/amd/gpu/rocm/README.html#validate-the-microservices-and-megaservice">Validate the MicroServices and MegaService</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of CodeTrans on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/docker_compose/intel/hpu/gaudi/README.html">Build Mega Service of CodeTrans on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/kubernetes/intel/README.html">Deploy CodeTrans in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/kubernetes/intel/README_gmc.html">Deploy CodeTrans in a Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/CodeTrans/ui/svelte/README.html">Code Translation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#dbqna-application">DBQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DBQnA/README.html">DBQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DBQnA/docker_compose/intel/cpu/xeon/README.html">Deploy on Intel Xeon Processor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DBQnA/ui/react/README.html">DBQnA React Application</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#docindexretriever-application">DocIndexRetriever Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocIndexRetriever/README.html">DocRetriever Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocIndexRetriever/docker_compose/intel/cpu/xeon/README.html">DocRetriever Application with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocIndexRetriever/docker_compose/intel/hpu/gaudi/README.html">DocRetriever Application with Docker</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#docsum-application">DocSum Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/README.html">Document Summarization Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/docker_compose/amd/gpu/rocm/README.html">Build and deploy DocSum Application on AMD GPU (ROCm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of Document Summarization on Intel Xeon Processor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of Document Summarization on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/kubernetes/intel/README.html">Deploy DocSum in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/kubernetes/intel/README_gmc.html">Deploy DocSum in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/kubernetes/intel/cpu/xeon/manifest/ui/README.html">Deploy DocSum with ReactUI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/ui/gradio/README.html">Document Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/ui/react/README.html">Doc Summary React</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/DocSum/ui/svelte/README.html">Doc Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#edgecraftrag-application">EdgeCraftRAG Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/EdgeCraftRAG/README.html">Edge Craft Retrieval-Augmented Generation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#faqgen-application">FaqGen Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/README.html">FAQ Generation Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/benchmark/accuracy/README.html">FaqGen Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/benchmark/performance/README.html">FaqGen Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/docker_compose/amd/gpu/rocm/README.html">Build and deploy FaqGen Application on AMD GPU (ROCm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of FAQ Generation on Intel Xeon Processor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of FAQ Generation on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/kubernetes/intel/README.html">Deploy FaqGen in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/kubernetes/intel/cpu/xeon/manifest/README_react_ui.html">Deploy FaqGen with ReactUI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/ui/react/README.html">Doc Summary React</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/FaqGen/ui/svelte/README.html">FAQ Generation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#graphrag-application">GraphRAG Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/GraphRAG/README.html">GraphRAG Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/GraphRAG/ui/react/README.html">ChatQnA Conversational UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/GraphRAG/ui/svelte/README.html">ChatQnA Customized UI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#instructiontuning-application">InstructionTuning Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/InstructionTuning/README.html">Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/InstructionTuning/docker_compose/intel/cpu/xeon/README.html">Deploy Instruction Tuning Service on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/InstructionTuning/docker_compose/intel/hpu/gaudi/README.html">Deploy Instruction Tuning Service on Gaudi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#multimodalqna-application">MultimodalQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/MultimodalQnA/README.html">MultimodalQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/MultimodalQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of MultimodalQnA on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/MultimodalQnA/docker_compose/intel/hpu/gaudi/README.html">Build Mega Service of MultimodalQnA on Gaudi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#productivitysuite-application">ProductivitySuite Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ProductivitySuite/README.html">Productivity Suite Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ProductivitySuite/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of Productivity Suite on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ProductivitySuite/docker_compose/intel/cpu/xeon/keycloak_setup_guide.html">🔐 Keycloak Configuration Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ProductivitySuite/kubernetes/intel/README.html">🚀 Deploy ProductivitySuite with ReactUI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/ProductivitySuite/ui/react/README.html">Productivity Suite React UI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#rerankfinetuning-application">RerankFinetuning Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/RerankFinetuning/README.html">Rerank Model Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/RerankFinetuning/docker_compose/intel/cpu/xeon/README.html">Deploy Rerank Model Finetuning Service on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/RerankFinetuning/docker_compose/intel/hpu/gaudi/README.html">Deploy Rerank Model Finetuning Service on Gaudi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#searchqna-application">SearchQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/SearchQnA/README.html">SearchQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/SearchQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of SearchQnA on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/SearchQnA/docker_compose/intel/hpu/gaudi/README.html">Build Mega Service of SearchQnA on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/SearchQnA/kubernetes/intel/README_gmc.html">Deploy SearchQnA in a Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/SearchQnA/ui/svelte/README.html">Neural Chat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#text2image-application">Text2Image Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Text2Image/README.html">Text-to-Image Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Text2Image/docker_compose/intel/cpu/xeon/README.html">Deploy Text-to-Image Service on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Text2Image/docker_compose/intel/hpu/gaudi/README.html">Deploy Text-to-Image Service on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Text2Image/ui/svelte/README.html">Text2Image Customized UI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#translation-application">Translation Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/README.html">Translation Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of Translation on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of Translation on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/kubernetes/intel/README.html">Deploy Translation in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/kubernetes/intel/README_gmc.html">Deploy Translation in a Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/Translation/ui/svelte/README.html">Language Translation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#videoqna-application">VideoQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VideoQnA/README.html">VideoQnA Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VideoQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of VideoQnA on Xeon</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#visualqna-application">VisualQnA Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/README.html">Visual Question and Answering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/benchmark/performance/README.html">VisualQnA Benchmarking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/docker_compose/intel/cpu/xeon/README.html">Build Mega Service of VisualQnA on Xeon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/docker_compose/intel/hpu/gaudi/README.html">Build MegaService of VisualQnA on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/kubernetes/intel/README.html">Deploy VisualQnA in Kubernetes Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/VisualQnA/kubernetes/intel/README_gmc.html">Deploy VisualQnA in a Kubernetes Cluster</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/examples.html#workflowexecagent-application">WorkflowExecAgent Application</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/WorkflowExecAgent/README.html">Workflow Executor Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/WorkflowExecAgent/tests/README.html">Validate Workflow Agent Microservice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIExamples/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIExamples/docker_images_list.html">Docker Images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/docker_images_list.html#example-images">Example images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/docker_images_list.html#microservice-images">Microservice images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIExamples/supported_examples.html">Supported Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIExamples/supported_examples.html#chatqna">ChatQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#codegen">CodeGen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#codetrans">CodeTrans</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#docsum">DocSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#language-translation">Language Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#searchqna">SearchQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#visualqna">VisualQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#videoqna">VideoQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#rerankfinetuning">RerankFinetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#instructiontuning">InstructionTuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#docindexretriever">DocIndexRetriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#agentqna">AgentQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#audioqna">AudioQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#faqgen">FaqGen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#multimodalqna">MultimodalQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIExamples/supported_examples.html#productivitysuite">ProductivitySuite</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../microservices/index.html">GenAI Microservices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../GenAIComps/README.html">Generative AI Components (GenAIComps)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#genaicomps">GenAIComps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/README.html#installation">Installation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#microservice">MicroService</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#megaservice">MegaService</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#gateway">Gateway</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#contributing-to-opea">Contributing to OPEA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIComps/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#agent-microservice">Agent Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html">Agent Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html#overview">1. Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html#start-agent-microservice">🚀2. Start Agent Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html#validate-microservice">🚀 3. Validate Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html#provide-your-own-tools">🚀 4. Provide your own tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/README.html#customize-agent-strategy">5. Customize agent strategy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/src/strategy/planexec/README.html">Plan Execute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/agent/langchain/src/strategy/ragagent/README.html">RAG Agent</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#animation-microservice">Animation Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html">Avatar Animation Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#start-microservice-with-docker-option-1">🚀1. Start Microservice with Docker (option 1)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#build-the-docker-images">1.1 Build the Docker images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#set-environment-variables">1.2. Set environment variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#run-the-docker-container">🚀2. Run the Docker container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#run-wav2lip-microservice">2.1 Run Wav2Lip Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#run-animation-microservice">2.2 Run Animation Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#validate-microservice">🚀3. Validate Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#validate-wav2lip-service">3.1 Validate Wav2Lip service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/animation/wav2lip/README.html#validate-animation-service">3.2 Validate Animation service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#asr-microservice">Asr Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/asr/whisper/README.html">ASR Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/asr/whisper/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/asr/whisper/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#chathistory-microservice">Chathistory Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/chathistory/README.html">📝 Chat History Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/chathistory/README.html#features">🛠️ Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/chathistory/README.html#implementation">⚙️ Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/chathistory/mongo/README.html">📝 Chat History Microservice with MongoDB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/chathistory/mongo/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/chathistory/mongo/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/chathistory/mongo/README.html#invoke-microservice">✅ Invoke Microservice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#cores-microservice">Cores Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/cores/telemetry/README.html">Telemetry for OPEA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/cores/telemetry/README.html#metrics">Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/cores/telemetry/README.html#tracing">Tracing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/cores/telemetry/README.html#visualization">Visualization</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#dataprep-microservice">Dataprep Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html">Dataprep Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#use-lvm-large-vision-model-for-summarizing-image-data">Use LVM (Large Vision Model) for Summarizing Image Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-redis">Dataprep Microservice with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-milvus">Dataprep Microservice with Milvus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-qdrant">Dataprep Microservice with Qdrant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-pinecone">Dataprep Microservice with Pinecone</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-pgvector">Dataprep Microservice with PGVector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-vdms">Dataprep Microservice with VDMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-multimodal">Dataprep Microservice with Multimodal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/milvus/langchain/README.html">Dataprep Microservice with Milvus</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/milvus/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/milvus/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/milvus/langchain/README.html#consume-microservice">🚀3. Consume Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/milvus/langchain/README.html#troubleshooting">🚀4. Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/README.html">Multimedia to Text Services</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/README.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/README.html#getting-started">Getting Started</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/README.html#validate-microservices">Validate Microservices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/README.html#how-to-stop-remove-services">How to Stop/Remove Services</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html">Test Data for Document Summarization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#source-of-test-data">Source of Test Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#description-of-test-data">Description of Test Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#files">Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimedia2text/data/README.html#license">License</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimodal/redis/langchain/README.html">Dataprep Microservice for Multimodal Data with Redis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimodal/redis/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimodal/redis/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimodal/redis/langchain/README.html#status-microservice">🚀3. Status Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/multimodal/redis/langchain/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/langchain/README.html">Dataprep Microservice with Neo4J</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/langchain/README.html#start-microservice-with-python">🚀Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/langchain/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/langchain/README.html#invoke-microservice">Invoke Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/llama_index/README.html">Dataprep Microservice with Neo4J</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/llama_index/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/llama_index/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/neo4j/llama_index/README.html#invoke-microservice">Invoke Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/pgvector/langchain/README.html">Dataprep Microservice with PGVector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pgvector/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pgvector/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pgvector/langchain/README.html#consume-microservice">🚀3. Consume Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/pinecone/langchain/README.html">Dataprep Microservice with Pinecone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pinecone/langchain/README.html#start-microservice-with-python">🚀Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pinecone/langchain/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/pinecone/langchain/README.html#invoke-microservice">Invoke Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/qdrant/langchain/README.html">Dataprep Microservice with Qdrant</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/qdrant/langchain/README.html#start-microservice-with-python">🚀Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/qdrant/langchain/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/qdrant/langchain/README.html#invoke-microservice">Invoke Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/redis/README.html">Dataprep Microservice with Redis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/redis/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/redis/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/redis/README.html#status-microservice">🚀3. Status Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/redis/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/README.html">Dataprep Microservice with VDMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/README.html#status-microservice">🚀3. Status Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/multimodal_langchain/README.html">Multimodal Dataprep Microservice with VDMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/multimodal_langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/multimodal_langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/multimodal_langchain/README.html#status-microservice">🚀3. Status Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/dataprep/vdms/multimodal_langchain/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#embeddings-microservice">Embeddings Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html">Embeddings Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html#embeddings-microservice-with-tei">Embeddings Microservice with TEI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html#embeddings-microservice-with-mosec">Embeddings Microservice with Mosec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html#embeddings-microservice-with-multimodal">Embeddings Microservice with Multimodal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html#embeddings-microservice-with-multimodal-clip">Embeddings Microservice with Multimodal Clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/README.html#embeddings-microservice-with-prediction-guard">Embeddings Microservice with Prediction Guard</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/README.html">build Mosec endpoint docker image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/README.html#build-embedding-microservice-docker-image">build embedding microservice docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/README.html#launch-mosec-endpoint-docker-container">launch Mosec endpoint docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/README.html#launch-embedding-microservice-docker-container">launch embedding microservice docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/README.html#run-client-test">run client test</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/dependency/README.html">Embedding Server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/dependency/README.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/mosec/langchain/dependency/README.html#quick-start">2. Quick Start</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal/README.html">Multimodal Embeddings Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal/README.html#consume-embedding-service">🚀3. Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal_clip/README.html">Multimodal CLIP Embeddings Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal_clip/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/multimodal_clip/README.html#consume-embedding-service">🚀2. Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/predictionguard/README.html">Embedding Generation Prediction Guard Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/predictionguard/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/predictionguard/README.html#consume-embeddings-service">🚀 Consume Embeddings Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/langchain/README.html">Embeddings Microservice with Langchain TEI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/langchain/README.html#start-microservice-with-docker-optional-2">🚀2. Start Microservice with Docker (Optional 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/langchain/README.html#consume-embedding-service">🚀3. Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/llama_index/README.html">Embeddings Microservice with Llama Index TEI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/llama_index/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/llama_index/README.html#start-microservice-with-docker-optional-2">🚀2. Start Microservice with Docker (Optional 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/embeddings/tei/llama_index/README.html#consume-embedding-service">🚀3. Consume Embedding Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#feedback-management-microservice">Feedback_management Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/feedback_management/README.html">🗨 Feedback Management Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/feedback_management/README.html#features">🛠️ Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/feedback_management/README.html#implementation">⚙️ Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/feedback_management/mongo/README.html">🗨 Feedback Management Microservice with MongoDB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/feedback_management/mongo/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/feedback_management/mongo/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#finetuning-microservice">Finetuning Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/finetuning/README.html">Fine-tuning Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/finetuning/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/finetuning/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/finetuning/README.html#consume-finetuning-service">🚀3. Consume Finetuning Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/finetuning/README.html#descriptions-for-finetuning-parameters">🚀4. Descriptions for Finetuning parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#guardrails-microservice">Guardrails Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/README.html">Trust and Safety with LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html">Bias Detection Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#future-development">Future Development</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#get-status-of-microservice">🚀3. Get Status of Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/bias_detection/README.html#consume-microservice-pre-llm-post-llm">🚀4. Consume Microservice Pre-LLM/Post-LLM</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html">Factuality Check Prediction Guard Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html#build-docker-images">Build Docker Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html#start-service">Start Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/factuality/predictionguard/README.html#consume-factuality-check-service">🚀 Consume Factuality Check Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/llama_guard/langchain/README.html">Guardrails Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/llama_guard/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/llama_guard/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/llama_guard/langchain/README.html#consume-guardrails-service">🚀3. Consume Guardrails Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html">PII Detection Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#ner-strategy">NER strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#ml-strategy">ML strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#input-and-output">Input and output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#get-status-of-microservice">🚀3. Get Status of Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html">PII Detection Prediction Guard Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html#build-docker-images">Build Docker Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html#start-service">Start Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/pii_detection/predictionguard/README.html#consume-pii-detection-service">🚀 Consume PII Detection Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html">Prompt Injection Detection Prediction Guard Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html#build-docker-images">Build Docker Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html#start-service">Start Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/prompt_injection/predictionguard/README.html#consume-prompt-injection-detection-service">🚀 Consume Prompt Injection Detection Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html">Toxicity Detection Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html#get-status-of-microservice">🚀3. Get Status of Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/README.html#consume-microservice-pre-llm-post-llm">🚀4. Consume Microservice Pre-LLM/Post-LLM</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html">Toxicity Checking Prediction Guard Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html#build-docker-images">Build Docker Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html#start-service">Start Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/toxicity_detection/predictionguard/README.html#consume-toxicity-check-service">🚀 Consume Toxicity Check Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/guardrails/wildguard/langchain/README.html">Guardrails Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/wildguard/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/wildguard/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/guardrails/wildguard/langchain/README.html#consume-guardrails-service">🚀3. Consume Guardrails Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#image2image-microservice">Image2image Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html">Image-to-Image Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#start-image-to-image-microservice">1.2 Start Image-to-Image Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#build-images">2.1 Build Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#start-image-to-image-service">2.2 Start Image-to-Image Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2image/README.html#test-image-to-image-service">3 Test Image-to-Image Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#image2video-microservice">Image2video Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html">Image-to-Video Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#start-svd-service">1.2 Start SVD Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#start-image-to-video-microservice">1.3 Start Image-to-Video Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#build-images">2.1 Build Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/image2video/README.html#start-svd-and-image-to-video-service">2.2 Start SVD and Image-to-Video Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#intent-detection-microservice">Intent_detection Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/intent_detection/langchain/README.html">Intent Detection Microservice by TGI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/intent_detection/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/intent_detection/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/intent_detection/langchain/README.html#consume-microservice">🚀3. Consume Microservice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#llms-microservice">Llms Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/tgi/langchain/README.html">TGI FAQGen LLM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/tgi/langchain/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/tgi/langchain/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/vllm/langchain/README.html">vLLM FAQGen LLM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/vllm/langchain/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/faq-generation/vllm/langchain/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/tgi/langchain/README.html">Document Summary TGI Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/tgi/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python 🐍 (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/tgi/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker 🐳 (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/tgi/langchain/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/vllm/langchain/README.html">Document Summary vLLM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/vllm/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python 🐍 (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/vllm/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker 🐳 (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/summarization/vllm/langchain/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html">LLM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#validated-llm-models">Validated LLM Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#clone-opea-genaicomps">Clone OPEA GenAIComps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/langchain/README.html">LLM Native Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/langchain/README.html#start-microservice">🚀1. Start Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/langchain/README.html#consume-llm-service">🚀2. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/llama_index/README.html">LLM Native Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/llama_index/README.html#start-microservice">🚀1. Start Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/native/llama_index/README.html#consume-llm-service">🚀2. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/ollama/langchain/README.html">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/ollama/langchain/README.html#get-started">Get Started</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/ollama/langchain/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/ollama/langchain/README.html#run-the-ollama-microservice">Run the Ollama Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/ollama/langchain/README.html#consume-the-ollama-microservice">Consume the Ollama Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/predictionguard/README.html">Prediction Guard Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/predictionguard/README.html#get-started">Get Started</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/predictionguard/README.html#consume-the-prediction-guard-microservice">Consume the Prediction Guard Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/tgi/README.html">TGI LLM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/tgi/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/tgi/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/tgi/README.html#consume-llm-service">🚀3. Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/langchain/README.html">vLLM Endpoint Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/langchain/README.html#set-up-environment-variables">🚀1. Set up Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/langchain/README.html#set-up-vllm-service">🚀2. Set up vLLM Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/langchain/README.html#set-up-llm-microservice">🚀3. Set up LLM microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/llama_index/README.html">vLLM Endpoint Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/llama_index/README.html#set-up-environment-variables">🚀1. Set up Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/llama_index/README.html#set-up-vllm-service">🚀2. Set up vLLM Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/text-generation/vllm/llama_index/README.html#set-up-llm-microservice">🚀3. Set up LLM microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/llms/utils/lm-eval/README.html">LM-Eval Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/llms/utils/lm-eval/README.html#cpu-service">CPU service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#lvms-microservice">Lvms Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/lvms/llama-vision/README.html">LVM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/llama-vision/README.html#start-microservice-with-docker">🚀 Start Microservice with Docker</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/lvms/llava/README.html">LVM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/llava/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/llava/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/lvms/predictionguard/README.html">LVM Prediction Guard Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/predictionguard/README.html#start-microservice-with-python">🚀1. Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/predictionguard/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/predictionguard/README.html#consume-lvm-service">🚀3. Consume LVM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/lvms/video-llama/README.html">LVM Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/video-llama/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/video-llama/README.html#test">✅ 2. Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/lvms/video-llama/README.html#clean">♻️ 3. Clean</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#nginx-microservice">Nginx Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/nginx/README.html">Nginx for Microservice Forwarding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/nginx/README.html#build-docker-image">🚀1. Build Docker Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/nginx/README.html#environment-settings">🚀2. Environment Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/nginx/README.html#start-nginx-service">🚀3. Start Nginx Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/nginx/README.html#consume-forwarded-service">🚀4. Consume Forwarded Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#prompt-registry-microservice">Prompt_registry Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/README.html">🧾 Prompt Registry Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/README.html#features">🛠️ Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/README.html#implementation">⚙️ Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/mongo/README.html">🧾 Prompt Registry Microservice with MongoDB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/mongo/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/prompt_registry/mongo/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#ragas-microservice">Ragas Microservice</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#reranks-microservice">Reranks Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/reranks/README.html">Reranking Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/README.html#features">🛠️ Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/README.html#implementation">⚙️ Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/reranks/fastrag/README.html">Reranking Microservice with fastRAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/fastrag/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/fastrag/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/fastrag/README.html#invoke-reranking-microservice">✅ 3. Invoke Reranking Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html">Reranking Microservice with Mosec</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html#build-reranking-mosec-image">Build Reranking Mosec Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html#build-reranking-microservice-image">Build Reranking Microservice Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html#launch-mosec-endpoint-image-container">Launch Mosec Endpoint Image Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html#launch-embedding-microservice-image-container">Launch Embedding Microservice Image Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/mosec/langchain/README.html#invoke-reranking-microservice">✅ Invoke Reranking Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/reranks/tei/README.html">Reranking Microservice via TEI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/tei/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/tei/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/tei/README.html#invoke-reranking-microservice">✅3. Invoke Reranking Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/reranks/videoqna/README.html">Rerank Microservice with VideoQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/videoqna/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/videoqna/README.html#invoke-reranking-microservice">✅ 2. Invoke Reranking Microservice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/reranks/videoqna/README.html#cleaning-the-container">♻️ 3. Cleaning the Container</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#retrievers-microservice">Retrievers Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-redis">Retriever Microservice with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-milvus">Retriever Microservice with Milvus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-pgvector">Retriever Microservice with PGVector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-pathway">Retriever Microservice with Pathway</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-qdrant">Retriever Microservice with QDrant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-vdms">Retriever Microservice with VDMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/README.html#retriever-microservice-with-multimodal">Retriever Microservice with Multimodal</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/milvus/langchain/README.html">Retriever Microservice with Milvus</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/milvus/langchain/README.html#start-microservice-with-python">🚀Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/milvus/langchain/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/milvus/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/multimodal/redis/langchain/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/multimodal/redis/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/multimodal/redis/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/multimodal/redis/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/langchain/README.html">Retriever Microservice with Neo4J</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/langchain/README.html#start-microservice-with-python">🚀Start Microservice with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/langchain/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/llama_index/README.html">Retriever Microservice with Neo4J</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/llama_index/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/neo4j/llama_index/README.html#invoke-microservice">Invoke Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/pathway/langchain/README.html">Retriever Microservice with Pathway</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/pathway/langchain/README.html#start-microservices">🚀Start Microservices</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/pgvector/langchain/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/pgvector/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/pgvector/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/pgvector/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/qdrant/haystack/README.html">Retriever Microservice with Qdrant</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/qdrant/haystack/README.html#start-microservice-with-python-option-1">1. 🚀Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/qdrant/haystack/README.html#start-microservice-with-docker-option-2">2. 🚀Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/qdrant/haystack/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/langchain/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/llama_index/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/llama_index/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/llama_index/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/redis/llama_index/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/retrievers/vdms/langchain/README.html">Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/vdms/langchain/README.html#visual-data-management-system-vdms">Visual Data Management System (VDMS)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/vdms/langchain/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/vdms/langchain/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/retrievers/vdms/langchain/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#text2image-microservice">Text2image Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html">Text-to-Image Microservice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#start-text-to-image-microservice">1.2 Start Text-to-Image Microservice</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#build-images">2.1 Build Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#start-text-to-image-service">2.2 Start Text-to-Image Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/text2image/README.html#test-text-to-image-service">3 Test Text-to-Image Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#texttosql-microservice">Texttosql Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/texttosql/README.html">🛢 Text-to-SQL Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/texttosql/README.html#features">🛠️ Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/texttosql/README.html#implementation">⚙️ Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/texttosql/langchain/README.html">🛢🔗 Text-to-SQL Microservice with Langchain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/texttosql/langchain/README.html#start-microservice-with-python-option-1">🚀 Start Microservice with Python（Option 1）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/texttosql/langchain/README.html#start-microservice-with-docker-option-2">🚀 Start Microservice with Docker (Option 2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/texttosql/langchain/README.html#invoke-the-microservice">✅ Invoke the microservice.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#tts-microservice">Tts Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/tts/gpt-sovits/README.html">GPT-SoVITS Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/gpt-sovits/README.html#build-the-image">Build the Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/gpt-sovits/README.html#start-the-service">Start the Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/gpt-sovits/README.html#test">Test</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/tts/speecht5/README.html">TTS Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/speecht5/README.html#start-speecht5-service-test">1.2 Start SpeechT5 Service/Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/speecht5/README.html#start-tts-service-test">1.3 Start TTS Service/Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/tts/speecht5/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#vectorstores-microservice">Vectorstores Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html">Vectorstores Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-redis">Vectorstores Microservice with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-qdrant">Vectorstores Microservice with Qdrant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-pgvector">Vectorstores Microservice with PGVector</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-pinecone">Vectorstores Microservice with Pinecone</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-pathway">Vectorstores Microservice with Pathway</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-milvus">Vectorstores Microservice with Milvus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-lancedb">Vectorstores Microservice with LanceDB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-chroma">Vectorstores Microservice with Chroma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-vdms">Vectorstores Microservice with VDMS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/chroma/README.html">Start Chroma server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/chroma/README.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/chroma/README.html#getting-started">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/lancedb/README.html">Start LanceDB Server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/lancedb/README.html#setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/lancedb/README.html#usage">Usage</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/milvus/README.html">Start Milvus server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/milvus/README.html#configuration">1. Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/milvus/README.html#run-milvus-service">2. Run Milvus service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pathway/README.html">Start the Pathway Vector DB Server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pathway/README.html#configuration">Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pathway/README.html#building-and-running">Building and running</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pathway/README.html#health-check-the-vector-store">Health check the vector store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pgvector/README.html">Start PGVector server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pgvector/README.html#download-pgvector-image">1. Download Pgvector image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pgvector/README.html#configure-the-username-password-and-dbname">2. Configure the username, password and dbname</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pgvector/README.html#run-pgvector-service">3. Run Pgvector service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pinecone/README.html">Pinecone setup</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pinecone/README.html#create-pinecone-account-from-the-below-link">1. Create Pinecone account from the below link</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pinecone/README.html#get-api-key">2. Get API key</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/pinecone/README.html#create-the-index-in-https-app-pinecone-io">3. Create the index in https://app.pinecone.io/</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/qdrant/README.html">Start Qdrant server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/qdrant/README.html#download-qdrant-image">1. Download Qdrant image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/qdrant/README.html#run-qdrant-service">2. Run Qdrant service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/redis/README.html">Start Redis server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/redis/README.html#download-redis-image">1. Download Redis image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/redis/README.html#run-redis-service">2. Run Redis service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/vectorstores/vdms/README.html">Start VDMS server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/vdms/README.html#download-vdms-image">1. Download VDMS image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/vectorstores/vdms/README.html#run-vdms-service">2. Run VDMS service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../microservices/index.html#web-retrievers-microservice">Web_retrievers Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIComps/comps/web_retrievers/chroma/langchain/README.html">Web Retriever Microservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIComps/comps/web_retrievers/chroma/langchain/README.html#start-microservice-with-docker">Start Microservice with Docker</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/index.html">Deploying GenAI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../GenAIInfra/README.html">GenAIInfra</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/README.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/README.html#prerequisite">Prerequisite</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/README.html#setup-kubernetes-cluster">Setup Kubernetes cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/README.html#optional-to-run-genaiinfra-on-intel-gaudi-product">(Optional) To run GenAIInfra on Intel Gaudi product</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/README.html#usages">Usages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/README.html#use-genai-microservices-connector-gmc-to-deploy-and-adjust-genaiexamples">Use GenAI Microservices Connector (GMC) to deploy and adjust GenAIExamples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/README.html#use-helm-charts-to-deploy">Use helm charts to deploy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIInfra/DEVELOPMENT.html">Development</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/DEVELOPMENT.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/DEVELOPMENT.html#testing">Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/DEVELOPMENT.html#pre-commit-testing">pre-commit testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIInfra/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html">Release Branches</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html#create-release-candidate-branch">1. Create release candidate branch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html#create-images-with-release-tag">2. Create images with release tag</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html#test-helm-charts">3. Test helm charts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html#test-gmc">4. Test GMC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/RELEASE_BRANCHES.html#publish-images">5. Publish images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#installation-guides">Installation Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../guide/installation/gmc_install/gmc_install.html">GenAI-microservices-connector(GMC) Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/gmc_install/gmc_install.html#genai-microservices-connector-gmc">GenAI-microservices-connector(GMC)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/gmc_install/gmc_install.html#install-gmc">Install GMC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/gmc_install/gmc_install.html#use-gmc-to-compose-a-chatqna-pipeline">Use GMC to compose a chatQnA Pipeline</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guide/installation/k8s_install/README.html">Kubernetes Installation Options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../guide/installation/k8s_install/k8s_instal_aws_eks.html">Kubernetes Installation using AWS EKS Cluster</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_instal_aws_eks.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_instal_aws_eks.html#create-aws-eks-cluster-in-aws-console">Create AWS EKS Cluster in AWS Console</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_instal_aws_eks.html#uploading-images-to-an-aws-private-registry">Uploading images to an AWS Private Registry</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html">Kubernetes installation demo using kubeadm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#node-configuration">Node configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#step-0-clean-up-the-environment">Step 0. Clean up the environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#step-1-install-relevant-components">Step 1. Install relevant components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#step-2-create-the-k8s-cluster">Step 2. Create the k8s cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#step-3-optional-reset-kubernetes-cluster">Step 3 (optional) Reset Kubernetes cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubeadm.html#notes">NOTES</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html">Kubernetes installation using Kubespray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#node-preparation">Node preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#step-1-set-up-kubespray-and-ansible">Step 1. Set up Kubespray and Ansible</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#step-2-build-your-own-inventory">Step 2. Build your own inventory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#step-3-define-kubernetes-configuration">Step 3. Define Kubernetes configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#step-4-deploy-kubernetes">Step 4. Deploy Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#step-5-create-kubectl-configuration">Step 5. Create kubectl configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../guide/installation/k8s_install/k8s_install_kubespray.html#quick-reference">Quick reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#authentication-and-authorization">Authentication and Authorization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/authN-authZ/README.html">Authentication and authorization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/README.html#istio-based-implementation-for-cloud-native-environments">Istio based implementation for cloud native environments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/README.html#apisix-based-implementation-for-cloud-native-environments">APISIX based implementation for cloud native environments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html">Authentication and Authorization with APISIX and OIDC based Identity provider (Keycloak)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html#update-values">Update values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html#install">Install</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-apisix/README.html#uninstall">Uninstall</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-istio/README.html">Leveraging Istio to compose an OPEA Pipeline with authentication and authorization enabled</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-istio/README.html#prerequisite">Prerequisite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-istio/README.html#perform-authentication-and-authorization-via-bearer-jwt-tokens-and-curl">Perform authentication and authorization via Bearer JWT tokens and curl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/authN-authZ/auth-istio/README.html#perform-authentication-and-authorization-via-oauth2-proxy-and-oidc-provider-and-ui">Perform authentication and authorization via oauth2-proxy and OIDC provider and UI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#helm-charts">Helm Charts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html">Helm charts for deploying GenAI Components and Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#helm-charts">Helm Charts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#deploy-with-helm-charts">Deploy with Helm charts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#helm-charts-options">Helm Charts Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#using-hpa-autoscaling">Using HPA (autoscaling)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#using-persistent-volume">Using Persistent Volume</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#using-private-docker-hub">Using Private Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/README.html#generate-manifests-from-helm-charts">Generate manifests from Helm Charts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/CI.html">CI guidelines for helm charts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/CI.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/CI.html#infra-setup">Infra Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/CI.html#add-new-test-case">Add new test case</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html">HorizontalPodAutoscaler (HPA) support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#pre-conditions">Pre-conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#gotchas">Gotchas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#enable-hpa">Enable HPA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/HPA.html#verify">Verify</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html">Monitoring support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html#pre-conditions">Pre-conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html#install">Install</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/monitoring.html#verify">Verify</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/agent/README.html">agent</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/agent/README.html#deploy">Deploy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/agent/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/agent/README.html#options">Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/asr/README.html">asr</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/asr/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/asr/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/asr/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/asr/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/chathistory-usvc/README.html">chathistory-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/chathistory-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/chathistory-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/chathistory-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/chathistory-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html">data-prep</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html#values">Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/data-prep/README.html#milvus-support">Milvus support</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/embedding-usvc/README.html">embedding-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/embedding-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/embedding-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/embedding-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/embedding-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/gpt-sovits/README.html">gpt-sovits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/gpt-sovits/README.html#install-the-chart">Install the chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/gpt-sovits/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/gpt-sovits/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/guardrails-usvc/README.html">guardrails-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/guardrails-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/guardrails-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/guardrails-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/guardrails-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/llm-uservice/README.html">llm-uservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/llm-uservice/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/llm-uservice/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/llm-uservice/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/llm-uservice/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/lvm-uservice/README.html">lvm-uservice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/lvm-uservice/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/lvm-uservice/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/lvm-uservice/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/lvm-uservice/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/mongodb/README.html">mongodb</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/mongodb/README.html#install-the-chart">Install the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/mongodb/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/mongodb/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/prompt-usvc/README.html">prompt-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/prompt-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/prompt-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/prompt-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/prompt-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/redis-vector-db/README.html">redis-vector-db</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/redis-vector-db/README.html#install-the-chart">Install the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/redis-vector-db/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/redis-vector-db/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/reranking-usvc/README.html">reranking-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/reranking-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/reranking-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/reranking-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/reranking-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html">retriever-usvc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html#values">Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/retriever-usvc/README.html#milvus-support">Milvus support</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/speecht5/README.html">speecht5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/speecht5/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/speecht5/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/speecht5/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tei/README.html">tei</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tei/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tei/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tei/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/teirerank/README.html">teirerank</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/teirerank/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/teirerank/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/teirerank/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tgi/README.html">tgi</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tgi/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tgi/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tgi/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tts/README.html">tts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tts/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tts/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tts/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/tts/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/vllm/README.html">vllm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/vllm/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/vllm/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/vllm/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/web-retriever/README.html">web-retriever</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/web-retriever/README.html#option1-installing-the-chart-separately">(Option1): Installing the chart separately</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/web-retriever/README.html#option2-installing-the-chart-with-dependencies-automatically">(Option2): Installing the chart with dependencies automatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/web-retriever/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/web-retriever/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/common/whisper/README.html">whisper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/whisper/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/whisper/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/common/whisper/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/agentqna/README.html">AgentQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/agentqna/README.html#deploy">Deploy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/agentqna/README.html#verify">Verify</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/audioqna/README.html">AudioQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/audioqna/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/audioqna/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/audioqna/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/README.html">ChatQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/README.html#values">Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/README.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html">ChatQnA Troubleshooting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#a-function-to-get-the-endpoint-of-service">a function to get the endpoint of service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#define-the-namespace-of-service">define the namespace of service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#update-a-file-to-database">Update a file to database</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#get-the-embedding-of-input">get the embedding of input</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#get-the-retriever-docs">get the retriever docs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#reranking-the-docs">reranking the docs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#tgi-q-and-a">TGI Q and A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/chatqna/troubleshooting.html#ref">REF</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/codegen/README.html">CodeGen</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codegen/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codegen/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codegen/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/codetrans/README.html">CodeTrans</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codetrans/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codetrans/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/codetrans/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/docsum/README.html">DocSum</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/docsum/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/docsum/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/docsum/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/faqgen/README.html">FaqGen</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/faqgen/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/faqgen/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/helm-charts/visualqna/README.html">VisualQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/visualqna/README.html#verify">Verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/helm-charts/visualqna/README.html#values">Values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#kubernetes-addons">Kubernetes Addons</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/README.html">Deploy Kubernetes add-ons for OPEA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Intel-Gaudi-Base-Operator/README.html">Intel® Gaudi® Base Operator for Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html">How-To Setup Observability for OPEA Workload in Kubernetes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#prepare">Prepare</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#setup-prometheus-grafana">1. Setup Prometheus &amp; Grafana</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#metrics-for-gaudi-hardware-v1-16-2">2. Metrics for Gaudi Hardware (v1.16.2)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#metrics-for-opea-applications">3. Metrics for OPEA applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#metrics-for-pcm-intel-performance-counter-monitor">4. Metrics for PCM (Intel® Performance Counter Monitor)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/Observability/README.html#more-dashboards">More dashboards</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/memory-bandwidth-exporter/README.html">memory bandwidth exporter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/memory-bandwidth-exporter/README.html#setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/kubernetes-addons/memory-bandwidth-exporter/README.html#more-flags-about-memory-bandwidth-exporter">More flags about memory bandwidth exporter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#microservices-connector">Microservices Connector</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/microservices-connector/README.html">genai-microservices-connector(GMC)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/README.html#description">Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/README.html#architecture">Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/README.html#personas">Personas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/README.html#getting-started">Getting Started</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/microservices-connector/troubleshooting_guide.html">Troubleshooting GMC Custom Resource（CR）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/microservices-connector/usage_guide.html">Usage guide for genai-microservices-connector(GMC)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-to-compose-a-chatqna-pipeline">Use GMC to compose a chatQnA Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-to-adjust-the-chatqna-pipeline">Use GMC to adjust the chatQnA Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-to-delete-the-chatqna-pipeline">Use GMC to delete the chatQnA Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-and-istio-to-compose-an-opea-pipeline-with-authentication-and-authorization-enabled">Use GMC and Istio to compose an OPEA Pipeline with authentication and authorization enabled</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/microservices-connector/config/samples/ChatQnA/use_cases.html">ChatQnA Use Cases in Kubernetes Cluster via GMC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/config/samples/ChatQnA/use_cases.html#using-prebuilt-images">Using prebuilt images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/config/samples/ChatQnA/use_cases.html#deploy-chatqna-pipeline">Deploy ChatQnA pipeline</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/microservices-connector/helm/README.html">Helm chart for genai-microservices-connector(GMC)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/helm/README.html#installing-the-gmc-helm-chart">Installing the GMC Helm Chart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/helm/README.html#check-the-installation-result">Check the installation result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/helm/README.html#next-step">Next step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/microservices-connector/helm/README.html#uninstall">Uninstall</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#pipeline-proxy">Pipeline Proxy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/proxy/README.html">OPEA Pipeline Proxy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/README.html#features">Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/README.html#build">Build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/README.html#deployment">Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/README.html#development">Development</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/proxy/deployments/guardrails/README.html">Guardrails</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/deployments/guardrails/README.html#architecture">Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/proxy/deployments/guardrails/README.html#deployment">Deployment</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html#scripts">Scripts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/scripts/README.html">Scripts and tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/scripts/nvidia/README.html">NVIDIA GPU Quick-Start Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/nvidia/README.html#prerequisite">Prerequisite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/nvidia/README.html#usages">Usages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/nvidia/README.html#faq-and-troubleshooting">FAQ and Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIInfra/scripts/ray/README.html">Deploy Autoscaling Ray Cluster with KubeRay in Kubernetes Cluster</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/ray/README.html#install-kuberay">Install KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/ray/README.html#start-ray-cluster-with-autoscaling">Start Ray Cluster with Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/ray/README.html#delete-ray-cluster-with-autoscaling">Delete Ray Cluster with Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIInfra/scripts/ray/README.html#uninstall-kuberay">Uninstall KubeRay</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../eval/index.html">Evaluating GenAI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/README.html">GenAIEval</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/README.html#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/README.html#evaluation">Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#lm-evaluation-harness">lm-evaluation-harness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#bigcode-evaluation-harness">bigcode-evaluation-harness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#kubernetes-platform-optimization">Kubernetes platform optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/README.html#benchmark">Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#features">Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#how-to-use">How to use</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/README.html#grafana-dashboards">Grafana Dashboards</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html">Kubernetes Platform Optimization with Resource Management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#nri-plugins">NRI Plugins</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#install">Install</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#validate-policy-status">Validate policy status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#configure">Configure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#validate-cpu-affinity-and-hardware-alignment-in-containers">Validate CPU affinity and hardware alignment in containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#remove-a-policy">Remove a policy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/doc/platform-optimization/README.html#nri-topology-aware-resource-policy">NRI topology-aware resource policy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html">OPEA Benchmark Tool</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#features">Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#installation">Installation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#prerequisites">Prerequisites</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#usage">Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#configuration">Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#test-suite-configuration">Test Suite Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/README.html#test-cases">Test Cases</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html">Auto-Tuning for ChatQnA: Optimizing Resource Allocation in Kubernetes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#key-features">Key Features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#usage">Usage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#configuration-files">Configuration Files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#hardrware-info-json">Hardrware_info.json</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#chatqna-neuralchat-rerank-latest-yaml">chatqna_neuralchat_rerank_latest.yaml</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#tuning-config-parameters">Tuning Config Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#output">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#auto-tuning-for-chatqna-optimizing-accuracy-by-tuning-model-related-parameters">Auto-Tuning for ChatQnA: Optimizing Accuracy by Tuning Model Related Parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/auto_tuning/README.html#run-the-tuning-script">Run the Tuning script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html">Setup Prometheus and Grafana to visualize microservice metrics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html#setup-prometheus">1. Setup Prometheus</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html#node-metrics-optional">1.1 Node Metrics (optional)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html#intel-gaudi-metrics-optional">1.2 Intel® Gaudi® Metrics (optional)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html#setup-grafana">2. Setup Grafana</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/grafana/README.html#import-grafana-dashboard">3. Import Grafana Dashboard</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/README.html">StressCli</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/README.html#stresscli-py">stresscli.py</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/README.html#prerequirements">Prerequirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/README.html#installation">Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/README.html#usage">Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/locust/README.html">locust scripts for OPEA ChatQnA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/locust/README.html#configuration-file">Configuration file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/benchmark/stresscli/locust/README.html#basic-usage">Basic Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html">HELMET: How to Evaluate Long-context Language Models Effectively and Thoroughly <img src="assets/logo.png" alt="HELMET" width="30"></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#quick-links">Quick Links</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#data">Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#running-evaluation">Running evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#model-based-evaluation">Model-based evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#adding-new-models">Adding new models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#adding-new-tasks">Adding new tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#others">Others</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#contacts">Contacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/HELMET/README.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html">CRAG Benchmark for Agent QnA systems</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#getting-started">Getting started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#crag-dataset">CRAG dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#launch-agent-qna-system">Launch agent QnA system</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#run-crag-benchmark">Run CRAG benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/agent_eval/crag_eval/README.html#use-llm-as-judge-to-grade-the-answers">Use LLM-as-judge to grade the answers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/autorag/evaluation/README.html">AutoRAG to evaluate the RAG system performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/autorag/evaluation/README.html#service-preparation">Service preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/autorag/evaluation/README.html#rag-evaluation">RAG evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/autorag/evaluation/README.html#notes">Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/deepeval/README.html">🚀 QuickStart</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/deepeval/README.html#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/deepeval/README.html#launch-service-of-llm-as-a-judge">Launch Service of LLM-as-a-Judge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/deepeval/README.html#writing-your-first-test-case">Writing your first test case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/deepeval/README.html#acknowledgements">Acknowledgements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html">🚀 QuickStart</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#launch-a-llm-service">Launch a LLM Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#example-1-tgi">Example 1: TGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#example-2-opea-llm">Example 2: OPEA LLM</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#predict">Predict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/longbench/README.html#evaluate">Evaluate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html">Evaluation Methodology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#prerequisite">Prerequisite</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#environment">Environment</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#multihop-english-dataset">MultiHop (English dataset)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#launch-service-of-rag-system">Launch Service of RAG System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#launch-service-of-llm-as-a-judge">Launch Service of LLM-as-a-Judge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#evaluation">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#crud-chinese-dataset">CRUD (Chinese dataset)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#id1">Prepare Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#id2">Launch Service of RAG System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#id3">Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/evaluation/rag_eval/README.html#acknowledgements">Acknowledgements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html">Metric Card for BLEU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#metric-description">Metric Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#intended-uses">Intended Uses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#how-to-use">How to Use</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#inputs">Inputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#output-values">Output Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#limitations-and-bias">Limitations and Bias</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#citation">Citation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/bleu/README.html#further-references">Further References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html">RAGAAF (RAG assessment - Annotation Free)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#run-ragaaf">Run RAGAAF</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#data">1. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#launch-endpoint-on-gaudi">2. Launch endpoint on Gaudi</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#model">3. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#metrics">4. Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragaaf/README.html#customizations">Customizations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../GenAIEval/evals/metrics/ragas/README.html">OPEA adaption of ragas (LLM-as-a-judge evaluation of Retrieval Augmented Generation)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragas/README.html#user-data">User data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragas/README.html#launch-huggingface-endpoint-on-intel-s-gaudi-machines">Launch HuggingFace endpoint on Intel’s Gaudi machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragas/README.html#run-opea-ragas-pipeline-using-your-desired-list-of-metrics">Run OPEA ragas pipeline using your desired list of metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../GenAIEval/evals/metrics/ragas/README.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developer-guides/index.html">Developer Guides</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer-guides/index.html#coding-guides">Coding Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../developer-guides/OPEA_API.html">OPEA API Service Spec (v1.0)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/OPEA_API.html#opea-mega-service-api">OPEA Mega Service API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/OPEA_API.html#opea-micro-service-api">OPEA Micro Service API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../developer-guides/index.html#documentation-guides">Documentation Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../developer-guides/doc_guidelines.html">Documentation Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#markdown-vs-restructuredtext">Markdown vs. RestructuredText</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#documentation-organization">Documentation Organization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#headings">Headings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#content-highlighting">Content Highlighting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#lists">Lists</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#multi-column-lists">Multi-Column Lists</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#tables">Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#file-names-and-commands">File Names and Commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#branch-specific-file-links">Branch-Specific File Links</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#internal-cross-reference-linking">Internal Cross-Reference Linking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#non-ascii-characters">Non-ASCII Characters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#include-content-from-other-files">Include Content from Other Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#code-and-command-examples">Code and Command Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#images">Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#tabs-spaces-and-indenting">Tabs, Spaces, and Indenting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#background-colors">Background Colors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#drawings">Drawings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#alternative-tabbed-content">Alternative Tabbed Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#instruction-steps">Instruction Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#first-instruction-step">First Instruction Step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#second-instruction-step">Second Instruction Step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/doc_guidelines.html#documentation-generation">Documentation Generation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../developer-guides/graphviz.html">Drawings Using Graphviz</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/graphviz.html#simple-directed-graph">Simple Directed Graph</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/graphviz.html#adding-edge-labels">Adding Edge Labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/graphviz.html#tables">Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/graphviz.html#finite-state-machine">Finite-State Machine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../developer-guides/docbuild.html">OPEA Documentation Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#documentation-overview">Documentation Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#set-up-the-documentation-working-folders">Set Up the Documentation Working Folders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#install-the-documentation-tools">Install the Documentation Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#documentation-presentation-theme">Documentation Presentation Theme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#run-the-documentation-processors">Run the Documentation Processors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#doc-build-troubleshooting">Doc Build Troubleshooting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#publish-content">Publish Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#document-versioning">Document Versioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../developer-guides/docbuild.html#filter-expected-warnings">Filter Expected Warnings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../community/index.html">OPEA Community</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#community-support">Community Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#resources">Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#contributing-guides">Contributing Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../community/CONTRIBUTING.html">Contribution Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/CONTRIBUTING.html#all-the-ways-to-contribute">All The Ways To Contribute</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CONTRIBUTING.html#support">Support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CONTRIBUTING.html#contributor-covenant-code-of-conduct">Contributor Covenant Code of Conduct</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../community/codeowner.html">OPEA Project Code Owners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#genaicomps-repository-code-owners">GenAIComps Repository Code Owners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#genaieval-repository-code-owners">GenAIEval Repository Code Owners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#genaiexamples-repository-code-owners">GenAIExamples Repository Code Owners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#genaiinfra-repository-code-owners">GenAIInfra Repository Code Owners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#docs-repository-code-owners">docs Repository Code Owners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/codeowner.html#continuous-integration-cicd-owners">Continuous Integration (CICD) owners</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../community/SECURITY.html">Reporting a Vulnerability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/SECURITY.html#script-usage-notice">Script Usage Notice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#roadmaps">Roadmaps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../roadmap/2024-2025.html">OPEA 2024 - 2025 Roadmap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#may-2024">May 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#june-2024">June 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#july-2024">July 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#aug-2024">Aug 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#sep-2024">Sep 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#q4-2024">Q4 2024</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/2024-2025.html#q1-2025">Q1 2025</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../roadmap/CICD.html">OPEA CI/CD Roadmap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/CICD.html#milestone-1-may-done">Milestone 1 (May, Done)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/CICD.html#milestone-2-june">Milestone 2 (June)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/CICD.html#milestone-3-july">Milestone 3 (July)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../roadmap/CICD.html#milestone-4-aug">Milestone 4 (Aug)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#project-governance">Project Governance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../community/charter.html">Technical Charter (the “Charter”) for OPEA a Series of LF Projects, LLC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#mission-and-scope-of-the-project">1. Mission and Scope of the Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#technical-steering-committee">2. Technical Steering Committee</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#tsc-voting">3. TSC Voting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#compliance-with-policies">4. Compliance with Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#community-assets">5. Community Assets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#general-rules-and-operations">6. General Rules and Operations.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#intellectual-property-policy">7. Intellectual Property Policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/charter.html#amendments">8. Amendments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../community/TSC.html">Technical Steering Committee (TSC)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/TSC.html#technical-steering-committee-members">Technical Steering Committee Members</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#our-pledge">Our Pledge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#our-standards">Our Standards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#enforcement-responsibilities">Enforcement Responsibilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#scope">Scope</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#enforcement">Enforcement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#enforcement-guidelines">Enforcement Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/CODE_OF_CONDUCT.html#attribution">Attribution</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../community/SECURITY.html">Reporting a Vulnerability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/SECURITY.html#script-usage-notice">Script Usage Notice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../community/index.html#rfc-proposals">RFC Proposals</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../community/rfcs.html">Request for Comments (RFCs)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html">24-05-16 GenAIExamples-001 Using MicroService to Implement ChatQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-05-16-OPEA-001-Overall-Design.html">24-05-16 OPEA-001 Overall Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-05-24-OPEA-001-Code-Structure.html">24-05-24 OPEA-001 Code Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-06-21-OPEA-001-DocSum_Video_Audio.html">24-06-21-OPEA-001-DocSum_Video_Audio</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-06-21-OPEA-001-Guardrails-Gateway.html">24-06-21-OPEA-001-Guardrails-Gateway</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-07-11-OPEA-Agent.html">24-07-11-OPEA-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-08-02-OPEA-AIAvatarChatbot.html">24-08-02-OPEA-AIAvatarChatbot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-08-07-OPEA-GenAIStudio.html">24-08-07 OPEA-001 OPEA GenAIStudio</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-08-20-OPEA-001-AI_Gateway_API.html">24-08-20-OPEA-001-AI Gateway API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-08-21-GenAIExample-002-Edge_Craft_RAG.html">24-08-21-GenAIExample-002-Edge Craft RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs/24-10-02-GenAIExamples-001-Image_and_Audio_Support_in_MultimodalQnA.html">24-10-02-GenAIExamples-001-Image_and_Audio_Support_in_MultimodalQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../community/rfcs.html#rfc-template">RFC Template</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes/index.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v1.1.html">OPEA Release Notes v1.1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v1.1.html#what-s-new-in-opea-v1-1">What’s New in OPEA v1.1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../release_notes/v1.1.html#highlights">Highlights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../release_notes/v1.1.html#notable-changes">Notable Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../release_notes/v1.1.html#full-changelogs">Full Changelogs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v1.1.html#contributors">Contributors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../release_notes/v1.1.html#contributing-organizations">Contributing Organizations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../release_notes/v1.1.html#individual-contributors">Individual Contributors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v1.0.html">OPEA Release Notes v1.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v1.0.html#whats-new-in-opea-v1-0">What’s New in OPEA v1.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v1.0.html#details">Details</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v0.9.html">OPEA Release Notes v0.9</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.9.html#whats-new-in-opea-v0-9">What’s New in OPEA v0.9</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.9.html#details">Details</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v0.8.html">OPEA Release Notes v0.8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.8.html#whats-new-in-opea-v0-8">What’s New in OPEA v0.8</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.8.html#details">Details</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.8.html#thanks-to-these-contributors">Thanks to these contributors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v0.7.html">OPEA Release Notes v0.7</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.7.html#opea-highlights">OPEA Highlights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.7.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.7.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.7.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.7.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes/v0.6.html">OPEA Release Notes v0.6</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.6.html#opea-highlight">OPEA Highlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.6.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.6.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.6.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes/v0.6.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing to OPEA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html#additional-content">Additional Content</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">OPEA Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-opea-s-mission">What is OPEA’s mission?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-opea">What is OPEA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-problems-are-faced-by-genai-deployments-within-the-enterprise">What problems are faced by GenAI deployments within the enterprise?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-now">Why now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-does-it-compare-to-other-options-for-deploying-gen-ai-solutions-within-the-enterprise">How does it compare to other options for deploying Gen AI solutions within the enterprise?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#will-opea-reference-implementations-work-with-proprietary-components">Will OPEA reference implementations work with proprietary components?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-does-opea-acronym-stand-for">What does OPEA acronym stand for?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-do-i-pronounce-opea">How do I pronounce OPEA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-initial-companies-and-open-source-projects-joined-opea">What initial companies and open-source projects joined OPEA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-intel-contributing">What is Intel contributing?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#when-you-say-technical-conceptual-framework-what-components-are-included">When you say Technical Conceptual Framework, what components are included?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-different-ways-partners-can-contribute-to-opea">What are the different ways partners can contribute to OPEA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-can-partners-see-the-latest-draft-of-the-conceptual-framework-spec">Where can partners see the latest draft of the Conceptual Framework spec?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#is-there-a-cost-for-joining">Is there a cost for joining?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-to-be-a-linux-foundation-member-to-join">Do I need to be a Linux Foundation member to join?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-can-i-report-a-bug-or-vulnerability">Where can I report a bug or vulnerability?</a></li>
</ul>
</li>
</ul>


        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OPEA™</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <!-- 1.1 -->
  
  

  <li><a href="../index.html">1.1</a> &raquo;</li>
  
     <li><a href="../introduction/index.html">OPEA Overview</a> &raquo;</li>
  
  <li>Open Platform for Enterprise AI (OPEA) Framework Draft Proposal</li>

      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/framework/framework.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
  
  
           <div itemprop="articleBody">
             
  <section id="open-platform-for-enterprise-ai-opea-framework-draft-proposal">
<h1>Open Platform for Enterprise AI (OPEA) Framework Draft Proposal<a class="headerlink" href="#open-platform-for-enterprise-ai-opea-framework-draft-proposal" title="Link to this heading">¶</a></h1>
<p>Rev 0.5     April 15, 2024</p>
<p>Initial draft by Intel. Contacts for content – Ke Ding (ke.ding&#64;intel.com ), Gadi Singer
(gadi.singer&#64;intel.com)</p>
<p>Feedback welcome at info&#64;opea.dev</p>
<section id="summary">
<h2>1. Summary<a class="headerlink" href="#summary" title="Link to this heading">¶</a></h2>
<p>OPEA (Open Platform for Enterprise AI) is a framework that enables the creation and evaluation of
open, multi-provider, robust and composable GenAI solutions that harness the best innovation across
the ecosystem.</p>
<p>OPEA is an ecosystem-wide program within the Linux Foundation Data &amp; AI framework that aims to
accelerate enterprise adoption of GenAI end-to-end solutions and realize business value. OPEA will
simplify the implementation of enterprise-grade composite GenAI solutions, including Retrieval
Augmented Generative AI (RAG). The platform is designed to facilitate efficient integration of secure,
performant, and cost-effective GenAI workflows into business systems and manage its deployments.</p>
<p>This platform’s definition will include an architectural blueprint, a comprehensive set of components for
GenAI systems, and a suite of specifications* for both individual components and entire systems. It will
also include tools for building, tuning, and evaluating end-to-end GenAI workflows. These definitions will
address key aspects such as performance, feature set, trustworthiness (security and transparency), and
readiness for enterprise-grade applications. The specifications will also include a set of reference flows
and demos that can be easily reproduced and adopted.</p>
<p><img alt="OPEAs Core Values" src="../_images/framework-image1.png" /></p>
<p>Figure 1-1: OPEA’s Core Values</p>
<p>*Disclaimer – The term ‘specification’ is used throughout this draft whitepaper and appendix as a broad
working term, referring generally to a detailed description of systems and their components. However, it
is important to note that this term might be replaced or updated based on more precise characterization
and applying the Linux Foundation licensing considerations.</p>
<p><img alt="proposed Construction and Evaluation Framework for AI Solutions" src="../_images/framework-image2.png" /></p>
<p>Figure 1-2 OPEA – proposed Construction and Evaluation Framework for AI Solutions</p>
<p>We are now in an era where AI algorithms and models, that were initially developed in research
environments and later introduced into consumer-focused settings, are now transitioning to widespread
enterprise deployment. This transition provides an opportunity for partners to leverage decades of
insights into enterprise-scale computing, security, trustworthiness, and datacenter integration, among
other areas, to accelerate AI adoption and unlock its potential value.</p>
</section>
<section id="introduction">
<h2>2. Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>Recently, the practices for developing AI solutions have undergone significant transformation. Instead of
considering AI model (e.g., a GenAI LLM) as the complete solution, these models are now being
integrated into more comprehensive end-to-end AI solutions. These solutions consist of multiple
components, including retrieval subsystems with embedding agents, a Vector Database for efficient
storage and retrieval, and prompt engines, among others. This shift has led to the emergence of
Composition Frameworks (such as LangChain or Haystack), which are used to assemble these
components into end-to-end GenAI flows, like RAG solutions, for the development and deployment of AI
solutions.</p>
<p>The ecosystem offers a range of composition frameworks, some are open-source (e.g., LangChain and
LlamaIndex), while others are closed-sourced and come bundled with professional services (e.g.,
ScaleAI). Additionally, some are offered by cloud service providers (e.g. AWS) or hardware/software
providers (e.g., NVIDIA). However, as of Q2 2024 these represent individual perspectives and offerings
for the intricate task of building an end-to-end AI solution.</p>
<section id="key-capabilities">
<h3>2.1 Key capabilities<a class="headerlink" href="#key-capabilities" title="Link to this heading">¶</a></h3>
<p>OPEA will offer key capabilities in both the Construction and Evaluation of end-to-end composite GenAI
solutions, that are built with retrieval augmentation. As a construction platform, OPEA will enable
creation of RAG-enabled AI solutions directly or through the use of compositional tools such as
LangChain and Haystack. As an evaluation framework, OPEA will provide the means to assess and grade
end-to-end composite GenAI solutions on aspects derived from four domains – performance, features,
trustworthiness and Enterprise-readiness.</p>
<section id="construction-of-genai-solutions-including-retrieval-augmentation">
<h4>2.1.1 Construction of GenAI solutions, including retrieval augmentation<a class="headerlink" href="#construction-of-genai-solutions-including-retrieval-augmentation" title="Link to this heading">¶</a></h4>
<p>Composing an end-to-end AI solution (including retrieval augmentation) can be done by combining
models and modules from multiple providers.</p>
<p>OPEA will offer or refer to a set of building blocks – models and modules – that can be called in a flow to
achieve an AI task or service. The models and modules can be part of OPEA repository, or published in
stable open repository (e.g., Hugging Face), or proprietary / closed source and cleared for use by an
OPEA assessment.</p>
<ul class="simple">
<li><p>GenAI models – Large Language Models (LLMs), Large Vision Models (LVMs), multimodal models, etc.</p></li>
<li><p>Other modules - AI system components (other than LLM/LVM models) including
Ingest/Data Processing module, Embedding Models/Services, Vector Databases
(aka Indexing or Graph data stores), Prompt Engines, Memory systems, etc.</p></li>
</ul>
<p>Each module for the system will be characterized with its expected functionality and attributes. Those
will be evaluated for every particular implementation choice (see following evaluation section). There
will be multiple options offered from various providers for each module and model, to allow for choice
and diversity.</p>
<p>This platform consists of a set of compositional capabilities that allow for building custom agents,
customizing AI assistants, and creating a full end-to-end GenAI flow that includes retrieval augmentation
as well as other functionality when needed. The platform will also include or reference tools for fine-
tuning as well as optimization (like quantization assists) to support creation of performant, robust
solutions that can run locally on target enterprise compute environments. Similar to building blocks, the
composition capabilities could be part of OPEA repository, or published in stable open repository (e.g.,
Hugging Face) or offered by the ecosystem (like LangChain, LlamaIndex and Haystack).</p>
<p>An important part of the compositional offering will be a set of validated reference flows that are ready
for downloading and recreation in the users’ environment. In the multitude of provided ready reference
flows, there will be domain-independent flows (like a RAG flow for language-based Q&amp;A, or a
multimodal flow to interact with one’s images and videos) that were tuned for different HW providers
and settings. There will also be domain-specific flows like financial service end-to-end flow or nutrition
adviser, which are sometimes called microservices.</p>
<p>There is a common visualizing language that is used to depict the component of each reference flow
being provided.</p>
</section>
<section id="evaluation-of-genai-solutions-including-retrieval-augmentation">
<h4>2.1.2 Evaluation of GenAI solutions, including retrieval augmentation:<a class="headerlink" href="#evaluation-of-genai-solutions-including-retrieval-augmentation" title="Link to this heading">¶</a></h4>
<p>OPEA will provide means and services to fully evaluate and grade components and end-to-end GenAI
solutions across four domains – performance, functionality, trustworthiness and enterprise-readiness.
The evaluation can be done on a flow created within OPEA, or created elsewhere but requesting to be
assessed through the platform.</p>
<p>Some of the evaluation tools will be part of the OPEA repository, while others will be references to
selected benchmarks offered by the ecosystem.</p>
<p>OPEA will offer tests for self-evaluation that can be done by the users. Furthermore, it will have the
engineering setup and staffing to provide evaluations per request.</p>
<p>The OPEA evaluations can be viewed at the following levels:</p>
<ul class="simple">
<li><p>Assessment – Detailed tests or benchmarks done for particular modules or
attributes of the end-to-end flow. Assessments will be elaborate and specific,
checking for the functionality and characteristics specified for that module
or flow.</p></li>
<li><p>Grading - Aggregation of the individual assessments to a grade per each of the
four domains – Performance, Features, Trustworthiness and
Enterprise-readiness. The aggregate grade per domain could be L1 Entry Level;
L2 Market Level; or L3 Advanced Level.</p></li>
<li><p>Certification – It has not yet been decided if certification will be offered
as part of OPEA.  However, the draft proposal for consideration is to allow
for OPEA Certification that will be determined by ensuring a minimum of Level
2 grading is achieved on all four domains.</p></li>
</ul>
<p><img alt="Key capabilities provided by OPEA" src="../_images/framework-image3.png" /></p>
<p>Figure 2-1 Key capabilities provided by OPEA</p>
<p>Appendix A of this document is an early draft of the proposed specification and sample reference flows.</p>
</section>
</section>
</section>
<section id="framework-components-architecture-and-flow">
<h2>3. Framework Components, Architecture and Flow<a class="headerlink" href="#framework-components-architecture-and-flow" title="Link to this heading">¶</a></h2>
<p>The OPEA definition (see Appendix A) includes characterization of components of State-of-the-Art (SotA)
composite systems including retrieval-augmentation and their architecture as a flow and SW stack.</p>
<p>There are six sections in the Appendix A which will provide a starting point for a more detailed and
elaborate joint OPEA definition effort:</p>
<ul class="simple">
<li><p>A1: System Components - List of ingredients that comprise a composed system,
along with their key characteristics. Some systems that will be evaluated may
only include a subset of these components.</p></li>
<li><p>A2: SW architecture - Diagram providing the layering of components in a SW stack</p></li>
<li><p>A3: System flows – Diagram[s] illustrating the flow of end-to-end operation
through the relevant components.</p></li>
<li><p>A4: Select specifications at system and component level</p></li>
<li><p>A5: Grading – Grading of systems being evaluated based on performance,
features, trustworthiness and enterprise-grade readiness.</p></li>
<li><p>A6: Reference Flows – List of reference flows that demonstrate key use-cases
and allow for downloading and replication for a faster path to create an
instantiation of the flow.</p></li>
</ul>
<p>Assumptions for the development of OPEA sections include:</p>
<ul class="simple">
<li><p>OPEA is a blueprint for composition frameworks and is not set to compete with
the popular frameworks. It is set to help assess the pros and cons of various
solutions and allow for improved interoperability of components.</p></li>
<li><p>In production, it is likely that many customers will deploy their own proprietary pipelines.</p></li>
<li><p>This framework blueprint is complementary and is intended to encourage
interoperability of system components as well as addition of specialized value
such as HW-aware optimizations, access to innovative features, and a variety
of assistants and microservices.</p></li>
<li><p>Flexible and allows easy pluggable and replaceable models and other
components. Ability to exchange components is an important factor in the fast
progression of the field.</p></li>
<li><p>Providing an environment to experiment with solution variations - e.g. What is
the impact (E2E system performance) when replacing a generic re-ranking
component with a particular provider’s re-ranking component.</p></li>
</ul>
<p>It should be noted that the final shaping of the framework components, architecture and flows will be
jointly defined by a technical committee as the full OPEA definition and governance structure is
established. It is also expected that there will be a regular cadence of updates to the spec to reflect the
rapidly shifting State-of-the-Art in the space.</p>
</section>
<section id="assessing-genai-components-and-flows">
<h2>4. Assessing GenAI components and flows<a class="headerlink" href="#assessing-genai-components-and-flows" title="Link to this heading">¶</a></h2>
<p>One of the important benefits to the ecosystem from the development and broad use of OPEA is a
structured set of evaluation that can provide trusted feedback on GenAI flows – whether composed
within OPEA, or composed elsewhere but has the visibility and access that allows for evaluations.
Evaluations can be done by assessing individual components or complete end-to-end GenAI solutions.
Evaluations in the OPEA context refer to assessment of individual aspects of a solution – like its latency
or accuracy per defined suite of tests. Assessments are covered in this section. Grading is an aggregation
of assessments and is covered in the next section.</p>
<p>Components and entire end-to-end flows will be evaluated in four domains – performance, features,
trustworthiness and enterprise-readiness.</p>
<p>Performance can be evaluated at the component level - e.g., Vector Database latency over a given large,
indexed dataset, or latency and throughput of an LLM model. Moreover, performance needs to be
evaluated for end-to-end solutions that perform defined tasks. The term ‘performance’ refers to aspects
of speed (e.g., latency), capacity (e.g., memory or context size) as well as accuracy or results.</p>
<p>OPEA can utilize existing evaluation specs like those used by SotA RAG systems and other standard
benchmarks wherever possible (e.g., MMLU). As for functionality, there are benchmarks and datasets
available to evaluate particular target functionality such as multi-lingual (like FLORES) or code
generations (e.g., Human-Eval).</p>
<p>For evaluating trustworthiness/Hallucination safety the spec will leverage existing benchmarks such
as  RGB benchmark/Truthful QA where possible.</p>
<p>Some assessment of enterprise readiness would include aspects of scalability (how large of data set the
system can handle, size of vector store, size and type of models), infrastructure readiness (cloud vs bare
metal), and software ease of deployment (any post-OPEA steps required for broad deployment). One of
the measures that could be assessed in this category is overall Cost/TCO of a full end-to-end GenAI flow.</p>
<p>When aspects of composite GenAI solutions are not freely available, reliable benchmarks or tests,
efforts will be made to ensure creation of such. As many of the current (early 2024) benchmarks are
focusing on performance and features, there will be an effort to complement those as needed for
assessing trustworthiness and enterprise-readiness.</p>
<p>The development of assessments should use learnings from similar evaluations when available. For
example, referring to RAG evaluation as reported by Cohere’s Nils Reimers.  See more details here:</p>
<ul class="simple">
<li><p>Human preference</p></li>
<li><p>Average accuracy of an E2E</p></li>
<li><p>Multi-lingual</p></li>
<li><p>Long-context “Needles in Haystack”</p></li>
<li><p>Domain specific</p></li>
</ul>
<p>The assessments development will be starting with focus on primary use-cases for RAG flow, such as
Open Q&amp;A. It will allow for comparison with common industrial evaluations (see Cohere, GPT-4)</p>
</section>
<section id="grading-structure">
<h2>5. Grading Structure<a class="headerlink" href="#grading-structure" title="Link to this heading">¶</a></h2>
<p>OPEA evaluation structure refers to specific tests and benchmarks as ‘assessments’ – see previous
section for details. ‘Grading’ is the part of OPEA evaluation that aggregates multiple individual
assessments into one of three levels, in each of the four evaluation domains – performance, features,
Trustworthiness and Enterprise readiness.</p>
<p>The following draft of a grading system is for illustration and discussion purposes only. A grading
system should be defined and deployed based on discussions in the technical review body and any other
governance mechanism that will be defined for OPEA.</p>
<p>To ensure that compositional systems are addressing the range of care-abouts for enterprise
deployment, the grading system has four categories:</p>
<ul class="simple">
<li><p>Performance – Focused on overall system performance and perf/TCO</p></li>
<li><p>Features- Mandatory and optional capabilities of system components</p></li>
<li><p>Trustworthiness – Ability to guarantee quality, security, and robustness. This
will take into account relevant government or other policies.</p></li>
<li><p>Enterprise Readiness – Ability to be used in production in enterprise environments.</p></li>
</ul>
<p>The Performance and Features capabilities are well understood by the communities and industry today,
while Trustworthiness and Enterprise Readiness are still in their early stage for assessment and
evaluation when it comes to GenAI solutions. Nevertheless, all domains are essential to ensure
performant, secure, privacy-aware, robust solutions ready for broad deployment.</p>
<p>The grading system is not intended to add any particular tests or benchmarks. All individual tests are to
be part of the assessments. Rather, the grading system goal is to provide an overall rating as to the
performance, functionality, trustworthiness and enterprise readiness of a GenAI flow over a multitude
of individual assessments. It is expected to provide an abstracted and simplified view of the GenAI flow
under evaluation. It will attempt to address two basic questions – what is the level of capabilities of a
flow relative to other flows evaluated at that time, as well as evaluate some necessary requirements
(such as for security and enterprise readiness) for robust deployment of GenAI solutions at scale. A
grading system establishes a mechanism to evaluate different constructed AI solutions (such as
particular RAG flows) in the context of the OPEA framework.</p>
<p>For each category, the assessments will be set with 3 levels:</p>
<ul class="simple">
<li><p>L1 – Entry Level – Limited capabilities. The solution might be seen as less
advanced or performant relative to other solutions assessed for similar tasks.
It might encounter issues in deployment (if deficiencies in trustworthiness or
enterprise readiness).</p></li>
<li><p>L2 – Market – Meets market needs. The solution represents that mid-range of
systems being reviewed and assessed. It can be safely deployed in production
enterprise environments and is expected to meet prevalent standards on
security and transparency.</p></li>
<li><p>L3 – Advanced – Exceeds average market needs. The solution represents the
top-range of components or end-to-end GenAI flows being reviewed and assessed
at the time. It meets or exceeds all security, privacy, transparency and
deployment-at-scale requirements.</p></li>
</ul>
<p>The grading system can be used by GenAI users to ensure that the solution being evaluated is meeting
the ecosystem expectations in a field that is moving exceptionally fast. It can highlight exceptional
solutions or point out areas of concern. The structured approach across the four domains ensures that
the combined learnings of the ecosystem at any given time are being reflected in the feedback to the
prospective users of a particular GenAI solution. Naturally, the goal posts of what is defined as L1/L2/L3
need to be updated on regular basis as the industry pushes GenAI State-of-the-Art forward.</p>
<p><img alt="Overall view of the grading system across four domains" src="../_images/framework-image4.png" /></p>
<p>Figure 5-1 Overall view of the grading system across four domains</p>
<p>The grading system can play a different role for the providers of models, building blocks (modules), and
complete end-to-end GenAI solutions. Providers can get structured and impartial feedback on the
strengths and weaknesses of their offering compared with the rest of the market. An articulation of all
key areas for enterprise deployment is expected to guide providers towards a more robust and
complete delivery and continuous improvement for broad enterprise deployment. It also serves to
highlight outstanding solutions, providing them tailwinds as the present and differentiate their offering.</p>
<p>If and when certification becomes part of the framework (discussion and decisions to be made at a later
stage) it is assumed that a system needs to be at least at Level 2 for every aspect to be “OPEA Certified”.
Such certification can increase the confidence of both providers and users that the GenAI solution being
evaluated is competitive and ready for broad deployment – stopping short of promising a guarantee of
any sort.</p>
<p>The assessment test suites and associated grading will allow for ISVs and industry solution adopters to
self-test, evaluate and grade themselves on the various metrics. The test suite will be comprised of
applicable tests/benchmarks currently available in the community and where no standard benchmarks
exist, new tests will be developed. For each of these metrics we will have a grading mechanism to map
particular score ranges to L1, L2 or L3 for that time. These ranges will be updated periodically to reflect
the advancements in the field.</p>
<p>Figure 5-2 illustrates some of the aspects to be evaluated in the four domains. Yellow highlighted
examples show the minimal assessments needed for each of the domains. The blue highlighted
examples show the next level of assessments that indicate higher level capabilities of the RAG pipeline.
The next level and the highest level of assessments are indicated by text with no color.</p>
<p><img alt="Capabilities and Testing Phases" src="../_images/framework-image5.png" /></p>
<p>Figure 5-2 Capabilities and Testing Phases</p>
</section>
<section id="reference-flows">
<h2>6. Reference flows<a class="headerlink" href="#reference-flows" title="Link to this heading">¶</a></h2>
<p>Reference flows are end-to-end instantiations of use cases within the OPEA framework. They represent
a specific selection of interoperable components to create an effective implementation of a GenAI
solution. Reference flows documentation and links need to include comprehensive information
necessary for users of the framework to recreate and execute the flow, reproducing the results reported
for the flow.  The reference flow documentation will provide links to the required components (which
may come from multiple providers) and the necessary script and other software required to run them.</p>
<p>Several flows will exclusively focus on open models and other components, providing full transparency
when necessary. Other flows may include proprietary components that can be called/activated within
those flows. However, the components being referred to in a reference flow must be accessible to OPEA
users – whether they are open source or proprietary, free to use or fee-based.</p>
<p>Reference Flows serve several primary objectives:</p>
<ul class="simple">
<li><p>Demonstrate representative instantiations: Within OPEA framework, reference
flows showcase specific uses and tasks. Given the framework’s inherent
flexibility, various combinations of components are possible allowing for
maximum flexibility. Reference flows demonstrate how specific paths and
combinations can be effectively implemented within the framework.</p></li>
<li><p>Highlight the framework’s potential: By offering optimized reference flows
that excel in performance, features, trustworthiness, and enterprise
readiness, users can gain insight into what can be achieved. The experience
serves as valuable learning tools towards achieving their AI deployment goals
and planning.</p></li>
<li><p>Facilitate easy deployment: Reference flows are designed to be accessible and
easy to instantiate with relatively low effort. It allows replicating a
functional flow within their environment with minimal effort, allowing
subsequent modifications as needed.</p></li>
<li><p>Encourage innovation and experimentation: Allow users in the ecosystem to
experiment with and innovate with a broad set of flows and maximize the value
for their end-to-end use cases.</p></li>
</ul>
<p>OPEA will deploy and evolve a visualization language to capture the blueprint flows (e.g., a base flow for
RAG chat/Q&amp;A) as well as to document the choices made for every reference flow. The visualization has
a legend (see Figure 6-1) that illustrates the key choices in the reference flow (e.g., sequence of
functions or containerization) (see Figure 6-2) as well as the implementation choices for particular
model and modules (See Appendix A section A6).</p>
<p><img alt="Legend for Blueprint and Reference Flows" src="../_images/framework-image6.png" /></p>
<p>Figure 6-1 Legend for Blueprint and Reference Flows</p>
<p><img alt="Example of blueprint RAG flow" src="../_images/framework-image7.png" /></p>
<p>Figure 6-2 Example of blueprint RAG flow</p>
<p>The Reference flows section of the specification (Section A6 in Appendix A) provides an initial catalog of
reference flows, demonstrating common tasks and diverse combinations of hardware and AI
components. As this collection of reference flows is extended, there will be diverse set of solution
providers and variations of HW (Intel, NVIDIA and others) as well as AI models, modules and
construction.</p>
</section>
<section id="appendix-a-draft-opea-specifications">
<h2>Appendix A – Draft OPEA Specifications<a class="headerlink" href="#appendix-a-draft-opea-specifications" title="Link to this heading">¶</a></h2>
<p><strong>Rev 0.1     April 15, 2024</strong></p>
<p>The draft specifications are intended for illustration and discussion purposes. The appendix has six
sections:</p>
<ul class="simple">
<li><p>A1: System Components - List of ingredients that comprise a composed system,
along with their key characteristics.</p></li>
<li><p>A2: SW architecture - Diagram providing the layering of components in a SW stack</p></li>
<li><p>A3: System flows – Diagram[s] illustrating the flow of end-to-end operation
through the relevant components.</p></li>
<li><p>A4: Select specifications at system and component level</p></li>
<li><p>A5: Grading – Grading of systems being evaluated based on performance,
features, trustworthiness and enterprise-grade readiness.</p></li>
<li><p>A6: Reference Flows – List of reference flows that demonstrate key use-cases
and allow for downloading and replication for a faster path to create an
instantiation of the flow.</p></li>
</ul>
<p>This is an early draft of OPEA framework specification. It provides an initial view of the content and is
expected to be substantially expanded in future revisions.</p>
<p>Disclaimer – The term ‘specification’ is used throughout this draft whitepaper and appendix as a broad
working term, referring generally to a detailed description of systems and their components. However, it
is important to note that this term might be replaced or updated based on more precise characterization
and applying the Linux Foundation licensing considerations.</p>
<section id="a1-system-components">
<h3>A1: System Components<a class="headerlink" href="#a1-system-components" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Components</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>OSS Examples</p></th>
<th class="head"><p>Proprietary Examples</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Agent framework</p></td>
<td><p>Orchestration software for building and deploying workflows combining information retrieval components with LLMs for building AI agents with contextualized information</p></td>
<td><p>Langchain, LlamaIndex, Haystack, Semantic Kernel</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>Ingest/Data Processing</p></td>
<td><p>Software components that can be used to enhance the data that is indexed for retrieval. For example: process, clean, normalization, information extraction, chunking, tokenization, meta data enhancement.</p></td>
<td><p>NLTK, spaCY, HF Tokenizers, tiktoken, SparkNLP</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Embedding models/service</p></td>
<td><p>Models or services that convert text chunks into embedding vectors to be stored in a vector database</p></td>
<td><p>HF Transformers, S-BERT</p></td>
<td><p>HF TEI, OpenAI, Cohere, GCP, Azure embedding APIs, JinaAI</p></td>
</tr>
<tr class="row-odd"><td><p>Indexing/Vector store</p></td>
<td><p>A software for indexing information (sparse/vector) and for retrieving given a query</p></td>
<td><p>Elasticsearch, Qdrant, Milvus, ChromaDB, Weaviate, FAISS, Vespa, HNSWLib, SVS, PLAID</p></td>
<td><p>Pinecone, Redis</p></td>
</tr>
<tr class="row-even"><td><p>Retrieval/Ranking</p></td>
<td><p>A SW component that can re-evaluate existing contexts relevancy order</p></td>
<td><p>S-BERT, HF Transformers, Bi/Cross-encoders, ColBERT</p></td>
<td><p>Cohere</p></td>
</tr>
<tr class="row-odd"><td><p>Prompt engine</p></td>
<td><p>A component that creates task specific prompts given queries and contexts, tracks user sessions (maintain history/memory)</p></td>
<td><p>Langchain hub</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Memory</p></td>
<td><p>Conversation history in memory and/or persistent database</p></td>
<td><p>Langchain Memory module, vLLM (automatic prefix caching)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p>LLM engine/service</p></td>
<td><p>LLM inference engine that generate text responses based on given prompts and contexts retrieved</p></td>
<td><p>vLLM, Ray, TensorRT-LLM</p></td>
<td><p>HF TGI, Deci Infery</p></td>
</tr>
<tr class="row-even"><td><p>LLM Models</p></td>
<td><p>Open-source and close-source models.</p></td>
<td><p>LLama2-7B,13B, Falcon 40B, Mixtral-7b, Gemma etc.</p></td>
<td><p>LLama2-70B, OpenAI, Cohere, Gemini, etc.</p></td>
</tr>
<tr class="row-odd"><td><p>Guardrails</p></td>
<td><p>A software component for enforcing compliance, filtering, safe responses</p></td>
<td><p>LLM Guard</p></td>
<td><p>Purple llama, OpenAI safety control, NEMO-Guardrails</p></td>
</tr>
<tr class="row-even"><td><p>Evaluation</p></td>
<td><p>Methods to evaluate compliance, Performance, Accuracy, Error rate of the LLM response</p></td>
<td><p>Recall, MAP, MTEB, MTBench, MMLU, TriviaQA, TruthfulQA…</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Figure A1.1 List of key components.</p>
</section>
<section id="a2-sw-architecture">
<h3>A2: SW Architecture<a class="headerlink" href="#a2-sw-architecture" title="Link to this heading">¶</a></h3>
<p>Support model selection and data integration across popular user-facing frameworks. It leverages
popular agent frameworks (aka orchestration frameworks or AI Construction Platforms) for developer
productivity and availability of platform optimization.</p>
<p>Tuning of the solutions leverage platform optimizations via popular domain frameworks such as Hugging
Face ecosystem to reduce developer complexity and provide flexibility across platforms.</p>
<p>![OPEA solution stack](images/framework-image8.png]</p>
<p>Figure A2.1 – OPEA solution stack.</p>
</section>
<section id="a3-system-flows">
<h3>A3: System Flows<a class="headerlink" href="#a3-system-flows" title="Link to this heading">¶</a></h3>
<p><img alt="Main OPEA system RAG flow" src="../_images/framework-image9.png" /></p>
<p>Figure A3.1 – Main OPEA system RAG flow.</p>
</section>
<section id="a4-select-specifications">
<h3>A4: Select Specifications<a class="headerlink" href="#a4-select-specifications" title="Link to this heading">¶</a></h3>
<p>Evaluating a composite generative AI system requires a view of end-to-end capabilities as well as assessment of individual components.</p>
<section id="a4-1-end-to-end-assessment">
<h4>A4.1 End-to-end assessment<a class="headerlink" href="#a4-1-end-to-end-assessment" title="Link to this heading">¶</a></h4>
<p>Following are some examples of assessments addressing the four domains - performance, features, trustworthiness and enterprise readiness.</p>
<section id="performance">
<h5>Performance<a class="headerlink" href="#performance" title="Link to this heading">¶</a></h5>
<ul class="simple">
<li><p>Overall System Performance</p>
<ul>
<li><p>Latency (first token latency, average token latency, streaming vs non-streaming output)</p></li>
<li><p>Throughput</p></li>
<li><p>Given a fixed combination of various components of RAG (specific vendor instance for each component), overall system performance.</p></li>
<li><p>For a specific task/domain, list the combination that would give the best system performance.</p></li>
</ul>
</li>
<li><p>Q&amp;A evaluation (accuracy)</p>
<ul>
<li><p>Task: Open Q&amp;A</p></li>
<li><p>Databases: NQ, TriviaQA and HotpotQA</p></li>
<li><p>Metric: Average Accuracy</p></li>
<li><p>Indexing: KILT Wikipedia</p></li>
</ul>
</li>
</ul>
</section>
<section id="features-functionality">
<h5>Features / Functionality<a class="headerlink" href="#features-functionality" title="Link to this heading">¶</a></h5>
<ul class="simple">
<li><p>Functional</p>
<ul>
<li><p>Features – multimodal, Multi-LLM, Multiple embedding model choices, multiple Embedding DBs, context length</p></li>
<li><p>Context Relevance (context precision/recall)</p></li>
<li><p>Groundedness/faithfulness</p></li>
<li><p>Answer Relevance</p></li>
</ul>
</li>
<li><p>Multi-step reasoning</p>
<ul>
<li><p>Task: 3-shot multi-hop REACT agents</p></li>
<li><p>Databases: Wikipedia (HotPotQA), Internet (Bamboogle)</p></li>
<li><p>Metric: Accuracy</p></li>
<li><p>Test sets: Reflexion, Ofir Press</p></li>
</ul>
</li>
<li><p>Multi-lingual</p>
<ul>
<li><p>Task: Semantic Search</p></li>
<li><p>Search Quality</p></li>
<li><p>Metric nDCG &#64;10</p></li>
<li><p>18 languages</p></li>
<li><p>Benchmark: MIRCAL</p></li>
</ul>
</li>
<li><p>Multi-lingual</p>
<ul>
<li><p>Tasks: Multilingual MMLU, Machine Translation</p></li>
<li><p>Metric: Accuracy, BLEU</p></li>
<li><p>French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, and Chinese</p></li>
<li><p>Benchmark: FLORES, MMLU</p></li>
</ul>
</li>
<li><p>Conversational agent and Function calling</p>
<ul>
<li><p>Task: conversational tool-use and single-turn function-calling capabilities</p></li>
<li><p>Benchmark-1: Microsoft’s ToolTalk</p></li>
<li><p>Benchmark-2: Berkeley’s Function Calling Leaderboard (BFCL)</p></li>
<li><p>Tool-use Metric: Soft Success rate</p></li>
<li><p>Function calls: Function Pass rate</p></li>
</ul>
</li>
<li><p>Human reference on enterprise RAG use cases</p>
<ul>
<li><p>Domains: Customer support, Workplace support (Tech), Workplace Assistant (Media), Tech FAQ</p></li>
<li><p>Metric: Win ratio vs. Mixtral</p></li>
</ul>
</li>
</ul>
</section>
<section id="enterprise-readiness">
<h5>Enterprise readiness<a class="headerlink" href="#enterprise-readiness" title="Link to this heading">¶</a></h5>
<p>Enterprise Readiness Assessment involving assessing for the following:</p>
<ol class="arabic simple">
<li><p>Scalability</p></li>
<li><p>Production deployability</p></li>
<li><p>Updatability</p></li>
<li><p>Observability/Debuggability</p></li>
</ol>
<p>Scalability is associated with the ability of RAG system to scale the size/dimensions of different components such as the following example metrics:</p>
<ul class="simple">
<li><p>Vector DB size</p></li>
<li><p>Dimensionality of retriever (the value of K in top-K documents)</p></li>
<li><p>Maximum context length supported by the generator</p></li>
<li><p>Parameter size of the generator models</p></li>
<li><p>Embedding dimension size</p></li>
</ul>
<p>Production deploy-ability Readiness includes various capabilities such as</p>
<ul class="simple">
<li><p>Efficient inference serving</p></li>
<li><p>Integrations with different enterprise systems such as Slack/workday/SAP/Databases</p></li>
<li><p>Enterprise grade RAS capabilities</p></li>
<li><p>Service Level Agreements (SLAs) on factuality, verifiability, performance enforceability</p></li>
</ul>
<p>Updatability includes capability for</p>
<ul class="simple">
<li><p>Rolling upgrade</p></li>
<li><p>Online upgrade</p></li>
<li><p>Component level upgrade</p></li>
</ul>
<p>Observability/Debuggability includes capability for</p>
<ul class="simple">
<li><p>Error detection and attribution to component</p></li>
<li><p>Early detection of component degradation</p></li>
<li><p>Trace generation to debug failures (functional and performance)</p></li>
<li><p>Traceability of each intermediate step (prompts for chained LLMs)</p></li>
</ul>
<p>Examples for observability include Databricks Inference Tables/Phoenix Open Inference Traces or
Langsmith Observability/monitoring features.</p>
</section>
</section>
<section id="a4-2-individual-components-assessment">
<h4>A4.2 Individual Components Assessment<a class="headerlink" href="#a4-2-individual-components-assessment" title="Link to this heading">¶</a></h4>
<p>Evaluation of individual components (modules) will include:</p>
<ul class="simple">
<li><p>Data preprocessing pipeline</p></li>
<li><p>Embedding – Quality/Storage/Processing time</p></li>
<li><p>Chunker, Retriever &amp; Re-ranker</p></li>
<li><p>Generator LLM – quality/latency/context length/reasoning ability/function calling/tool usage</p></li>
<li><p>Auto evaluation vs Manul evaluation</p></li>
<li><p>Observability</p></li>
<li><p>Guardrails -</p></li>
<li><p>Prompting</p></li>
<li><p>Output Generation – structured/grammar/output types(json/text)</p></li>
</ul>
<p>Early example of next level articulation of metrics expected per each major component.</p>
<p>Component Name: Retriever</p>
<ul class="simple">
<li><p>Metric:  Normalized Discounted Cumulative Gain&#64;10 with BEIR benchmark datasets or other QA datasets</p></li>
<li><p>Metric: Context Recall&#64;k</p></li>
<li><p>Metric: Context Precision&#64;k</p></li>
<li><p>Metric: Hit Rate</p></li>
</ul>
<p>Component Name: LLM/Generation</p>
<ul class="simple">
<li><p>Metric: Faithfulness – How factually correct is the generated answer (computed as a ragas metrics between 0 and 1)</p></li>
<li><p>Metric: Answer Relevance – how relevant generated answer to the query
(computed as a ragas metrics between 0 and 1)</p></li>
</ul>
</section>
</section>
<section id="a5-grading">
<h3>A5: Grading<a class="headerlink" href="#a5-grading" title="Link to this heading">¶</a></h3>
<p>To ensure that compositional systems are addressing the range of care-abouts for enterprise
deployment, the grading system has four categories:</p>
<ul class="simple">
<li><p>Performance – Focused on overall system performance and perf/TCO</p></li>
<li><p>Features- Mandatory and optional capabilities of system components</p></li>
<li><p>Trustworthiness – Ability to guarantee quality, security, and robustness.</p></li>
<li><p>Enterprise Ready – Ability to be used in production in enterprise environments.</p></li>
</ul>
<p>For each category, the assessments will be set with 3 levels</p>
<ul class="simple">
<li><p>L1 – Entry Level – Limited capabilities. Solution acceptable for PoC, but not production.</p></li>
<li><p>L2 – Market – Meets market needs. Can be deployed in production.</p></li>
<li><p>L3 – Advanced – Exceeds market needs.</p></li>
</ul>
<p>Part of the recommendation is to have a certification (if and when it becomes part of the framework)
process. It is assumed that a system needs to be at least at Level 2 for every aspect to be “OPEA
Certified”.</p>
<section id="a5-1-performance-grading">
<h4>A5.1 Performance Grading<a class="headerlink" href="#a5-1-performance-grading" title="Link to this heading">¶</a></h4>
<p>Performance grading is based on running a set of vertical-specific end-to-end use cases on full system
and capturing the relevant metrics during the run.</p>
<ul class="simple">
<li><p>E2E/System View</p>
<ul>
<li><p>Vendors have flexibility to innovate/differentiate their implementations within the black box</p></li>
</ul>
</li>
<li><p>Running a fixed set of use cases</p>
<ul>
<li><p>Covering different vertical scenarios</p></li>
<li><p>Minimum level of accuracy and reliability</p></li>
</ul>
</li>
<li><p>Input Datasets for benchmark</p>
<ul>
<li><p>Open/publicly available</p></li>
<li><p>Automatic generation</p></li>
</ul>
</li>
<li><p>Scale factors</p>
<ul>
<li><p>Supports different input magnitude size</p></li>
</ul>
</li>
<li><p>Metrics</p>
<ul>
<li><p>First-token latency, overall latency, throughput, cost, consistency</p></li>
<li><p>Formula to aggregate metrics for final score</p></li>
<li><p>Vertical-specific metrics</p></li>
</ul>
</li>
</ul>
<section id="performance-grade">
<h5>Performance Grade<a class="headerlink" href="#performance-grade" title="Link to this heading">¶</a></h5>
<p>Performance grade is based on a set of ‘black box’ end-to-end RAG benchmarks, based on real use
cases. Each solution submitted to the OpenRag alliance will be measured against it. Performance
measurements will include latency, throughput, scalability, accuracy and consistency.</p>
<ul class="simple">
<li><p>Level 1 – Baseline benchmark complete</p></li>
<li><p>Level 2 – Meets performance levels that are expected for the bulk of GenAI solutions performing
similar benchmarks/tasks.</p></li>
<li><p>Level 3 – Exceeds the performance of most solutions being evaluated at that time. Top-tier
solutions per the tasks evaluated.</p></li>
</ul>
</section>
</section>
<section id="a5-2-features-grading">
<h4>A5.2 Features Grading<a class="headerlink" href="#a5-2-features-grading" title="Link to this heading">¶</a></h4>
<p>Feature grading consists of running functional tests to test system capabilities in a number of different
domains. Each domain will have its own score.</p>
<ul class="simple">
<li><p>Interoperability/API</p>
<ul>
<li><p>Functional tests for each interface</p></li>
<li><p>Different granularity levels for components</p></li>
<li><p>Open interfaces for 3rd party data sources</p></li>
<li><p>Should enable multiple types of data sources</p></li>
</ul>
</li>
<li><p>Platform capabilities and AI methods</p>
<ul>
<li><p>Ingest, inference, fine tuning</p></li>
<li><p>Gen AI and reinforcement learning</p></li>
</ul>
</li>
<li><p>User experience</p>
<ul>
<li><p>Ease of Use</p></li>
<li><p>Management tools – single pane, inter-vendor</p></li>
<li><p>GUI requirements</p></li>
<li><p>Developer tools</p></li>
</ul>
</li>
<li><p>Deployment models</p>
<ul>
<li><p>Orchestration</p></li>
<li><p>K8, hypervisor</p></li>
</ul>
</li>
<li><p>Compliance</p>
<ul>
<li><p>Potential certification (if and when it becomes part of the framework) based on functional testing</p></li>
</ul>
</li>
</ul>
<section id="features-grade">
<h5>Features Grade<a class="headerlink" href="#features-grade" title="Link to this heading">¶</a></h5>
<p>Features evaluated for interoperability, platform capabilities, user experience (ease of use), AI
methods being applied, and specialized functionality.</p>
<ul class="simple">
<li><p>Level 1 – Single model and accesses few data sources; Limited data ingest;
Basic or no development tools; basic UI; bare metal, manual install.</p></li>
<li><p>Level 2 - Multiple models, and accesses diverse enterprise data sources; full
data ingest; basic fine-tuning; flexible pipelining of modules in the flow;
basic agent controls.</p></li>
<li><p>Level 3 – Natively supports multimodal models and data source; Advanced
development tools with SotA fine-tuning and optimizations capabilities;
leading specialized features</p></li>
</ul>
</section>
</section>
<section id="a5-3-trustworthiness-grading">
<h4>A5.3 Trustworthiness Grading<a class="headerlink" href="#a5-3-trustworthiness-grading" title="Link to this heading">¶</a></h4>
<p>Trustworthiness and responsible AI are evolving in an operational sense. See NIST trustworthy and
responsible AI  and the EU AI Act. While these efforts are evolving, for the interim, we propose grading
solution trustworthiness along the axes of security, reliability, transparency, and confidence:</p>
<ul class="simple">
<li><p>Transparency</p>
<ul>
<li><p>Open Source Models and Code. This provides visibility into the actual code running, being able to verify versions and signed binaries.</p></li>
<li><p>Open standards, reusing existing standards.</p></li>
<li><p>Data sets used in model training, which allows analysis of data distribution and any biases therein. For instance, if a cancer detection model was trained on populations that are very diverse - ethnically (genome), or environments (exposure to carcinogens), it carries with a risk of applicability when used for individuals that are not representative of the training set.</p></li>
<li><p>Citing sources/documents used in generating responses, protecting from hallucinations. One of the chief benefits of RAG.</p></li>
<li><p>Meeting regulatory requirements such as ISO27001, HIPAA, and FedRAMP as appropriate.</p></li>
</ul>
</li>
<li><p>Security:</p>
<ul>
<li><p>Role-based access control, segmented access per user-role regardless of same model use. This could be a pre or post processing step that filters out data based on user access to different information. For instance, executive leadership may have access to company revenues, financials and customer lists versus an engineer.</p></li>
<li><p>Solutions that run at the minimum necessary process privilege to prevent exploits form escalation of privileges should the application be hacked.</p></li>
<li><p>Running in trusted execution environments, that is hardware supported confidential compute environments that protect data in use – providing confidentiality and integrity from privileged and other processes running on the same infrastructure. Valuable particularly in the cloud.</p></li>
<li><p>Attesting binaries in use, be it models or software.</p></li>
<li><p>Audit logs that indicate when and what updates were applied either to models or other software, including security patches.</p></li>
<li><p>Ensuring that results, intermediate and final are persisted only on encrypted storage and shared with end users through secure transport.</p></li>
</ul>
</li>
<li><p>Reliability</p>
<ul>
<li><p>Provide the same answer, all else remaining the same, when prompts are similar, differing in their use of synonyms.</p></li>
<li><p>Returns correct answers, per tests.</p></li>
<li><p>Confidence</p></li>
<li><p>In question answering scenarios, awareness of the quality and how current/up-to-date data used in RAG and providing that information along with the response helps an end user in determining how confident they can be with a response.</p></li>
<li><p>Cites sources for responses. Meta data can also be used to indicate how up-to-date the input information is.</p></li>
<li><p>With respect to diagnosis/classification tasks, such as cancer detection, the divergence of the test subject from the training dataset is an indicator of applicability risk, confidence in the response (alluded to in data transparency above).</p></li>
</ul>
</li>
</ul>
<section id="trustworthiness-grade">
<h5>Trustworthiness Grade<a class="headerlink" href="#trustworthiness-grade" title="Link to this heading">¶</a></h5>
<p>Evaluating transparency, privacy protection and security aspects</p>
<ul class="simple">
<li><p>Level 1 – Documentation of aspects called for in trustworthiness domain</p></li>
<li><p>Level 2 - Supports role-based access controls  - information being accessed/retrieved is
available based on approval for the user (even if all users access the same model);</p></li>
<li><p>Level 3 - Supports security features (e.g., running Confidential Computing / Trusted
execution Environment). Supports attestation of the models being run; full open-
source transparency on pre-training dataset, weights, fine-tuning data/recipes</p></li>
</ul>
</section>
</section>
<section id="a5-4-enterprise-ready-grading">
<h4>A5.4 Enterprise-Ready Grading<a class="headerlink" href="#a5-4-enterprise-ready-grading" title="Link to this heading">¶</a></h4>
<p>Grading enterprise-readiness consists of evaluating the ability of the overall solution to be deployed in
production in an enterprise environment. The following criteria will be taken into account:</p>
<ul class="simple">
<li><p>Ability to have on-prem and cloud deployments</p>
<ul>
<li><p>At least two types of solution instances (on-premise installation, cloud, hybrid option)</p></li>
<li><p>Cloud/Edge-native readiness (refer to CNCF process/guidelines)</p></li>
</ul>
</li>
<li><p>Security-ready for enterprise</p>
<ul>
<li><p>Multi-level Access Control &amp; Response (including ability to integrate with internal tools)</p></li>
<li><p>Data &amp; Model Protection (e.g. including GDPR)</p></li>
<li><p>Lifecycle management including security updates, bug fixes, etc</p></li>
<li><p>Solutions that are packaged as containerized applications that do not run as root or have
more capabilities than necessary. OWASP container best practices.</p></li>
<li><p>Ensure by-products/interim results if saved to disk are done so after encrypting.</p></li>
</ul>
</li>
<li><p>Quality assurance</p>
<ul>
<li><p>Accuracy &amp; Uncertainty Metrics for domain-specific enterprise tasks</p></li>
<li><p>Documentation</p></li>
</ul>
</li>
<li><p>High availability</p>
<ul>
<li><p>Replication &amp; Data/Instance Protection</p></li>
<li><p>Resiliency – time to relaunch an instance when burned down to zero.</p></li>
<li><p>Provides support and instrumentation for enterprise 24/7 support</p></li>
</ul>
</li>
<li><p>Licensing model and SW Distribution</p>
<ul>
<li><p>Scalable from small to large customers</p></li>
<li><p>Ability to customize for specific enterprise needs</p></li>
</ul>
</li>
</ul>
<section id="enterprise-readiness-grade">
<h5>Enterprise Readiness Grade<a class="headerlink" href="#enterprise-readiness-grade" title="Link to this heading">¶</a></h5>
<p>Must first meet mins across performance, features, and trustworthiness</p>
<ul class="simple">
<li><p>Level 1 – Reference Design and deployment guide</p></li>
<li><p>Level 2 - Output ready for enterprise deployment (no post-OPEA steps needed);
containerized, K8 support; generally robust (but not guaranteed) for production
deployment at scale</p></li>
<li><p>Level 3 – Generating sophisticated monitoring and instrumentation for the enterprise
deployment environment. High resiliency – meeting fast time to relaunch an
instance. Allows for L2 + 24/7 support mode out-of-the-box</p></li>
</ul>
</section>
</section>
</section>
<section id="a6-reference-flows">
<h3>A6: Reference Flows<a class="headerlink" href="#a6-reference-flows" title="Link to this heading">¶</a></h3>
<p>This section includes descriptions of reference flows that will be available for loading and reproducing
with minimal effort.</p>
<p>Reference flows serve four primary objectives:</p>
<ul class="simple">
<li><p>Demonstrate representative instantiations: Within OPEA framework, reference
flows showcase specific uses and tasks. Given the framework’s inherent
flexibility, various combinations of components are possible allowing for
maximum flexibility. Reference flows demonstrate how specific paths and
combinations can be effectively implemented within the framework.</p></li>
<li><p>Highlight the framework’s potential: By offering optimized reference flows
that excel in performance, features, trustworthiness, and enterprise
readiness, users can gain insight into what can be achieved. The experience
serves as valuable learning tools towards achieving their AI deployment goals
and planning.</p></li>
<li><p>Facilitate easy deployment: Reference flows are designed to be accessible and
easy to instantiate with relatively lower effort. It allows replicating a
functional flow within their environment with minimal effort, allowing
subsequent modifications as needed.</p></li>
<li><p>Encourage innovation and experimentation: Allow users in the ecosystem to
experiment with and innovate with a broad set of flows and maximize the value
for their end-to-end use cases.</p></li>
</ul>
<p>Current examples of reference flows are provided for illustration purposes. The set of reference flows is
expected to grow and cover various combinations of HW and SW/AI components from multiple
providers.</p>
<p>The reference flow descriptions need to provide high clarity as to what and how they can be recreated
and results reproduced at an OPEA user setting. All reference flows will have a visualization that clarifies
which components are being instantiated and how they are connected in the flow. The graphics legend
described in Figure 6.1 will be used for all reference flow depictions.</p>
<p><img alt="Reference Design Flows Visualization - legend" src="../_images/framework-image10.png" /></p>
<p>Figure A6.1 - Reference Design Flows Visualization - legend</p>
<section id="a6-1-xeon-gaudi2-llm-rag-flow-for-chat-qna">
<h4>A6.1 – Xeon + Gaudi2 LLM RAG flow for Chat QnA<a class="headerlink" href="#a6-1-xeon-gaudi2-llm-rag-flow-for-chat-qna" title="Link to this heading">¶</a></h4>
<p>A reference flow that illustrates an LLM enterprise RAG flow that runs on Xeon (GNR) with vector
database and an embedding model, and with a Gaudi2 serving backend for LLM model inference.</p>
<p>The reference flow demonstrates a RAG application that provides an AI assistant experience with
capability of retrieving information from an external source to enhance the context that is provided to
an LLM. The AI assistant is provided with access to an external knowledge base, consisting of text and
PDF documents and web pages available via direct URL download.
The flow enables users to interact with LLMs and query about information that is unknown to the LLMs,
or for example, consists of proprietary data sources.</p>
<p>The reference flow consists of the following detailed process: a data storage which is used by a
retrieving module to retrieve relevant information given a query from the user. The query and external
data are stored in an encoded vector format that allows for enhance semantic search. The retriever
module encodes the query and provides the prompt processor the retrieved context and the query to
create an enhanced prompt to the LLM. An LLM receives the enhanced prompt generates a grounded
and correct response to the user.</p>
<p>The flow contains the following components:</p>
<ul class="simple">
<li><p>A data ingest flow that uses an embedding model serving platform (TEI) and an
embedding model (BGE-base) for encoding text and queries into semantic
representations (vectors) which are stored in an index (Redis vector
database), both running on Intel Gen6 Xeon GNR for storing and retrieving
data.</p></li>
<li><p>A LLM inference serving flow utilizing TGI-Gaudi for LLM model serving on
Gaudi2 platform, which is used generating answers by inputting prompts that
combine retrieved relevant documents from Redis vector database and the user
query.</p></li>
<li><p>An orchestration framework based on LangChain that initializes a pipeline with
the components above and orchestrates the data processing from the user
(query), text encoding, retrieval, prompt generation and LLM inference.</p></li>
</ul>
<p>A complete reference implementation of this flow is available in the ChatQnA example in Intel’s GenAI
examples repository.</p>
<p><img alt="Xeon + Gaudi2 LLM RAG flow for Chat QnA" src="../_images/framework-image11.png" /></p>
<p>Figure A6-1.2 Xeon + Gaudi2 LLM RAG flow for Chat QnA</p>
<p>A demo user Interface looks like below, which also shows the difference with and without RAG.</p>
<p><img alt="Xeon + Gaudi2 LLM RAG flow for Chat QnA – demo screen" src="../_images/framework-image12.png" /></p>
<p>Figure A6-1.3  Xeon + Gaudi2 LLM RAG flow for Chat QnA – demo screen</p>
</section>
<section id="a6-2-multimodal-chat-over-images-and-videos">
<h4>A6.2 - Multimodal Chat Over Images and Videos<a class="headerlink" href="#a6-2-multimodal-chat-over-images-and-videos" title="Link to this heading">¶</a></h4>
<p>This reference flow demonstrates a multimodal RAG pipeline which utilizes Intel Labs’ BridgeTower
vision-language model for indexing and LLaVA for inference, both running on Intel Gaudi AI accelerators.
The use case for this reference flow is enabling an AI chat assistant to retrieve and comprehend
multimodal context documents such as images and videos. For example, a user may wish to ask an AI
assistant questions which require reasoning over images and videos stored on their PC. This solution
enables such capabilities by retrieving images and video frames relevant to a user’s query and providing
them as extra context to a Large Vision-Language Model (LVLM), which then answers the user’s
question.</p>
<p>Specifically, this reference solution takes images and video files as input. The inputs are encoded in a
joint multimodal embedding space by BridgeTower, which is an open-source vision-language
transformer. Detailed instructions and documentation for this model are available via Hugging Face. The
multimodal embeddings are then indexed and stored in a Redis vector database.</p>
<p>At inference time, a user’s query is embedded by BridgeTower and used to retrieve the most relevant
images &amp; videos from the vector database. The retrieved contexts are then appended to the user’s
query and passed to LLaVA to generate an answer. Detailed instructions and documentation for the
LLaVA model are available via Hugging Face.</p>
<p>This reference flow requires Intel Gaudi AI Accelerators for the embedding model and for generating
responses with the LVLM. All other components of the reference flow can be executed on CPU. A
complete end-to-end open-source implementation of this reference flow is available via Multimodal
Cognitive AI.</p>
<p><img alt="Multimodal Chat Over Images and Videos Reference Flow" src="../_images/framework-image13.png" /></p>
<p>Figure A6-2.1 Multimodal Chat Over Images and Videos Reference Flow</p>
<p>Below is an illustration of a user interface constructed for this reference flow, which was showcased at
Intel Vision:</p>
<p><img alt="Multimodal Chat Over Images and Videos – demo screen" src="../_images/framework-image14.png" /></p>
<p>Figure A6.2.2 Multimodal Chat Over Images and Videos – demo screen</p>
</section>
<section id="a6-3-optimized-text-and-multimodal-rag-pipeline">
<h4>A6.3 – Optimized Text and Multimodal RAG pipeline<a class="headerlink" href="#a6-3-optimized-text-and-multimodal-rag-pipeline" title="Link to this heading">¶</a></h4>
<p>The reference flow below demonstrates an optimized Text and Multimodal RAG pipeline which can be
leveraged by Enterprise customers on Intel Xeon processor.</p>
<p>This flow demonstrates RAG inference flow on unstructured data and images with 4th and 5th Gen Intel
Xeon processor using Haystack. It is based on fastRAG for optimized retrieval.</p>
<p>The first step is to create index for the vector database (i.e. Qdrant in this case). For unstructured text
data, sentence-transformers  is used. For images, BridgeTower is used to encode the inputs.</p>
<p>Once the vector database is set up, next step is to deploy inference chat. The LLM and LMM models
used for inference are Llama-2-7b-chat-hf, Llama-2-13b-chat-hf and LLaVa models respectively.</p>
<p>The below diagram shows the end-to-end flow for this optimized text and multimodal chat with RAG.</p>
<p><img alt="Optimized Text and Multimodal RAG pipeline Reference Flow" src="../_images/framework-image15.png" /></p>
<p>Figure A6-3.1 Optimized Text and Multimodal RAG pipeline Reference Flow</p>
<p>Below is a visual snapshot of the chat implemented using this flow. It shows how a RAG-enabled chatbot
in Figure A6-3.2 improves the response for a Superbowl query over a non-RAG implementation in Figure
A6-3.3.</p>
<p><img alt="Non-RAG chatbot: Super Bowl Query" src="../_images/framework-image16.png" /></p>
<p>Figure A6-3.2: Non-RAG chatbot: Super Bowl Query</p>
<p><img alt="RAG enabled chatbot - Super Bowl query" src="../_images/framework-image17.png" /></p>
<p>Figure A6-3.3: RAG enabled chatbot - Super Bowl query</p>
</section>
</section>
</section>
</section>


           </div>
          </div>

          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../introduction/index.html" class="btn btn-neutral float-left" title="OPEA Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../getting-started/README.html" class="btn btn-neutral float-right" title="Getting Started with OPEA" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024 OPEA™, a Series of LF Projects, LLC.

<span class="lastupdated">Published on Nov 26, 2024.</span>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-3QH5804YP8"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-3QH5804YP8', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>